{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from _DESAdapter import DESAdapter, environment_requires_DES_adapter\n",
    "import mechanicalsoup\n",
    "\n",
    "def login(email, password):\n",
    "    \"\"\"\n",
    "    Logs in to kenpom.com using user credentials and returns an authenticated session.\n",
    "    \n",
    "    Args:\n",
    "        email (str): User e-mail for login to kenpom.com.\n",
    "        password (str): User password for login to kenpom.com.\n",
    "        \n",
    "    Returns:\n",
    "        session (requests.Session): Authenticated session with full access to kenpom.com.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix for Cloudflare SSL profiling\n",
    "    session = requests.Session()\n",
    "    if environment_requires_DES_adapter():\n",
    "        session.mount('https://kenpom.com/', DESAdapter())\n",
    "\n",
    "    # Create a StatefulBrowser to manage login\n",
    "    browser = mechanicalsoup.StatefulBrowser(session)\n",
    "    browser.set_user_agent('Mozilla/5.0')\n",
    "    browser.open('https://kenpom.com/index.php')\n",
    "\n",
    "    if 'Cloudflare' in browser.page.title.string:\n",
    "        raise Exception('Opening kenpom.com failed - request was intercepted by Cloudflare protection')\n",
    "\n",
    "    # Select and fill the login form\n",
    "    browser.select_form('form[action=\"handlers/login_handler.php\"]')\n",
    "    browser['email'] = email\n",
    "    browser['password'] = password\n",
    "\n",
    "    # Submit login form\n",
    "    response = browser.submit_selected()\n",
    "\n",
    "    if response.status_code != 200 or 'PHPSESSID=' not in response.headers.get('set-cookie', ''):\n",
    "        raise Exception('Logging in to kenpom.com failed - check that the site is available and your credentials are correct.')\n",
    "    \n",
    "    if 'subscription expired' in str(browser.get('https://kenpom.com/index.php').content):\n",
    "        raise Exception('Logging in to kenpom.com failed - account subscription is expired')\n",
    "\n",
    "    # Extract cookies from browser to use in the requests session\n",
    "    for cookie in browser.session.cookies:\n",
    "        session.cookies.set(cookie.name, cookie.value)\n",
    "    \n",
    "    return session\n",
    "    \n",
    "def get_table_data(email, password):\n",
    "    session = login(email, password)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://kenpom.com/\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "    \n",
    "\n",
    "    for season in ['2016','2017','2018','2019','2020','2021','2022','2023']:\n",
    "        for game in range(0,4000):\n",
    "            table_url = f\"https://kenpom.com/box.php?g={game}&y={season}\"\n",
    "            print(f\"Season: {season}, Game: {game}\")\n",
    "            response = session.get(table_url, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                \n",
    "                # Extract date\n",
    "                game_info = soup.find(\"span\", class_=\"game-info\")\n",
    "                print(game_info)\n",
    "                \n",
    "                date_str = game_info.text.strip().split(\" · \")[0]\n",
    "                \n",
    "                # Extract team names and scores from the scoreline\n",
    "                scoreline = soup.find(\"h2\", class_=\"scoreline\").text.strip()\n",
    "                print(scoreline)\n",
    "                # Use regex to extract team names and scores\n",
    "                team_scores = re.findall(r'([A-Za-z\\s.\\'&]+?)\\s(\\d+)', scoreline)\n",
    "                print(team_scores)\n",
    "                # Assign parsed values for home and away team names and scores\n",
    "                away_team, away_score = team_scores[0]\n",
    "                home_team, home_score = team_scores[1]\n",
    "                \n",
    "                # Convert scores to integers\n",
    "                away_score = int(away_score)\n",
    "                home_score = int(home_score)\n",
    "\n",
    "                # Extract half-time scores from the linescore table\n",
    "                linescore_table = soup.find(\"table\", id=\"linescore-table2\")\n",
    "                rows = linescore_table.find_all(\"tr\")[1:]  # Skip header row\n",
    "                \n",
    "                away_team_1h = int(rows[0].find_all(\"td\")[1].text) + int(rows[0].find_all(\"td\")[2].text)\n",
    "                home_team_1h = int(rows[1].find_all(\"td\")[1].text) + int(rows[1].find_all(\"td\")[2].text)\n",
    "\n",
    "                # Create DataFrame\n",
    "                data = {\n",
    "                    \"Date\": [date_str.strip(\"\\n\")],\n",
    "                    \"Home Team\": [away_team],\n",
    "                    \"Away Team\": [home_team],\n",
    "                    \"Home 1H Points\": [home_team_1h],\n",
    "                    \"Away 1H Points\": [away_team_1h],\n",
    "                    \"Home Full Points\": [away_score],\n",
    "                    \"Away Full Points\": [home_score],\n",
    "                }\n",
    "                \n",
    "                df = pd.DataFrame(data)\n",
    "            return df\n",
    "    #                 except:\n",
    "    #                     return None\n",
    "    #     else:\n",
    "    #         print(\"Failed to retrieve the page\")\n",
    "    #         return None\n",
    "\n",
    "\n",
    "    # import time\n",
    "\n",
    "\n",
    "    # # table_url = f\"https://kenpom.com/box.php?g=5&y=2013\"\n",
    "    # # table_data = get_table_data(email, password, table_url)\n",
    "\n",
    "    # for season in ['2016','2017','2018','2019','2020','2021','2022','2023']:\n",
    "    #     for game in range(0,4000):\n",
    "    #         table_url = f\"https://kenpom.com/box.php?g={game}&y={season}\"\n",
    "    #         print(f\"Season: {season}, Game: {game}\")\n",
    "    #         table_data = get_table_data(email, password, table_url)\n",
    "    #         df = pd.concat([df, table_data])\n",
    "    #         time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinkNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinkNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0b/h0zc244107jg60tttkl4r0kw0000gn/T/ipykernel_12498/2761133440.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dIMMITT2021$\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m headers = {\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Mozilla/5.0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0b/h0zc244107jg60tttkl4r0kw0000gn/T/ipykernel_12498/2120905217.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(email, password)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Select and fill the login form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'form[action=\"handlers/login_handler.php\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'email'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'password'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mechanicalsoup/stateful_browser.py\u001b[0m in \u001b[0;36mselect_form\u001b[0;34m(self, selector, nr)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'select_form failed for'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLinkNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfound_forms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinkNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "df = pd.DataFrame()\n",
    "email = \"nick@ncaainsiders.com\"\n",
    "password = \"dIMMITT2021$\"\n",
    "\n",
    "session = login(email, password)\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://kenpom.com/\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "    \n",
    "for season in ['2024']:\n",
    "    for game in range(0,1000):\n",
    "        time.sleep(0.44444)\n",
    "        table_url = f\"https://kenpom.com/box.php?g={game}&y={season}\"\n",
    "        print(f\"Season: {season}, Game: {game}\")\n",
    "        response = session.get(table_url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                \n",
    "                # Extract date\n",
    "                game_info = soup.find(\"span\", class_=\"game-info\")\n",
    "                print(game_info)\n",
    "                \n",
    "                date_str = game_info.text.strip().split(\" · \")[0]\n",
    "                \n",
    "                # Extract team names and scores from the scoreline\n",
    "                scoreline = soup.find(\"h2\", class_=\"scoreline\").text.strip()\n",
    "                print(scoreline)\n",
    "                # Use regex to extract team names and scores\n",
    "                team_scores = re.findall(r'([A-Za-z\\s.\\'&]+?)\\s(\\d+)', scoreline)\n",
    "                print(team_scores)\n",
    "                # Assign parsed values for home and away team names and scores\n",
    "                away_team, away_score = team_scores[0]\n",
    "                home_team, home_score = team_scores[1]\n",
    "                \n",
    "                # Convert scores to integers\n",
    "                away_score = int(away_score)\n",
    "                home_score = int(home_score)\n",
    "\n",
    "                # Extract half-time scores from the linescore table\n",
    "                linescore_table = soup.find(\"table\", id=\"linescore-table2\")\n",
    "                rows = linescore_table.find_all(\"tr\")[1:]  # Skip header row\n",
    "                \n",
    "                away_team_1h = int(rows[0].find_all(\"td\")[1].text) + int(rows[0].find_all(\"td\")[2].text)\n",
    "                home_team_1h = int(rows[1].find_all(\"td\")[1].text) + int(rows[1].find_all(\"td\")[2].text)\n",
    "\n",
    "                # Create DataFrame\n",
    "                data = {\n",
    "                    \"Date\": [date_str.strip(\"\\n\")],\n",
    "                    \"Home Team\": [away_team],\n",
    "                    \"Away Team\": [home_team],\n",
    "                    \"Home 1H Points\": [home_team_1h],\n",
    "                    \"Away 1H Points\": [away_team_1h],\n",
    "                    \"Home Full Points\": [away_score],\n",
    "                    \"Away Full Points\": [home_score],\n",
    "                }\n",
    "                \n",
    "                df1 = pd.DataFrame(data)\n",
    "                df = pd.concat([df,df1])\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predict/2024_games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"games/2016_1344.csv\")\n",
    "df1 = pd.read_csv(\"games/2016_2019.csv\")\n",
    "df2 = pd.read_csv(\"games/2017_2250.csv\")\n",
    "df3 = pd.read_csv(\"games/2018.csv\")\n",
    "df4 = pd.read_csv(\"games/2019_2020.csv\")\n",
    "df5 = pd.read_csv(\"games/2020.csv\")\n",
    "df6 = pd.read_csv(\"games/2021_2022.csv\")\n",
    "df7 = pd.read_csv(\"games/2022_2023.csv\")\n",
    "df8 = pd.read_csv(\"games/2023_2024.csv\")\n",
    "df9 = pd.read_csv(\"games/2024-1.csv\")\n",
    "df10 = pd.read_csv(\"games/2024-2.csv\")\n",
    "\n",
    "\n",
    "df = pd.concat([df,df1,df2,df3,df4,df5,df6,df7,df8,df9,df10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"games/games.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
