{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "game_df = pd.read_csv(\"data/train/game-info.csv\", index_col=0)\n",
    "game_df['date'] = pd.to_datetime(game_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "game_df['home_margin'] = game_df['home_score'] - game_df['away_score']\n",
    "game_df['away_margin'] = game_df['away_score'] - game_df['home_score']\n",
    "\n",
    "csv_files_2021 = glob.glob(\"daily_csvs_2021/*.csv\")\n",
    "daily_torvik_2021_df = pd.concat((pd.read_csv(f) for f in csv_files_2021), ignore_index=True)\n",
    "daily_torvik_2021_df = daily_torvik_2021_df[daily_torvik_2021_df['Team'] != \"Team\"]\n",
    "daily_torvik_2021_df['Team'] = daily_torvik_2021_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2021_df['WAB'] = daily_torvik_2021_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2021_df['season'] = 2021\n",
    "daily_torvik_2021_df = daily_torvik_2021_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2021_df.columns = ['season', 'date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "    \n",
    "csv_files_2022 = glob.glob(\"daily_csvs_2022/*.csv\")\n",
    "daily_torvik_2022_df = pd.concat((pd.read_csv(f) for f in csv_files_2022), ignore_index=True)\n",
    "daily_torvik_2022_df = daily_torvik_2022_df[daily_torvik_2022_df['Team'] != \"Team\"]\n",
    "daily_torvik_2022_df['Team'] = daily_torvik_2022_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2022_df['WAB'] = daily_torvik_2022_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2022_df['season'] = 2022\n",
    "daily_torvik_2022_df = daily_torvik_2022_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2022_df.columns = ['season','date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "csv_files_2023 = glob.glob(\"daily_csvs_2023/*.csv\")\n",
    "daily_torvik_2023_df = pd.concat((pd.read_csv(f) for f in csv_files_2023), ignore_index=True)\n",
    "daily_torvik_2023_df = daily_torvik_2023_df[daily_torvik_2023_df['Team'] != \"Team\"]\n",
    "daily_torvik_2023_df['Team'] = daily_torvik_2023_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2023_df['WAB'] = daily_torvik_2023_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2023_df['season'] = 2023\n",
    "daily_torvik_2023_df = daily_torvik_2023_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2023_df.columns = ['season','date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "csv_files_2024 = glob.glob(\"daily_csvs_2024/*.csv\")\n",
    "daily_torvik_2024_df = pd.concat((pd.read_csv(f) for f in csv_files_2024), ignore_index=True)\n",
    "daily_torvik_2024_df = daily_torvik_2024_df[daily_torvik_2024_df['Team'] != \"Team\"]\n",
    "daily_torvik_2024_df['Team'] = daily_torvik_2024_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2024_df['WAB'] = daily_torvik_2024_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2024_df['season'] = 2024\n",
    "daily_torvik_2024_df = daily_torvik_2024_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2024_df.columns = ['season','date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "csv_files_2025 = glob.glob(\"daily_csvs_2025/*.csv\")\n",
    "daily_torvik_2025_df = pd.concat((pd.read_csv(f) for f in csv_files_2025), ignore_index=True)\n",
    "daily_torvik_2025_df = daily_torvik_2025_df[daily_torvik_2025_df['Team'] != \"Team\"]\n",
    "daily_torvik_2025_df['Team'] = daily_torvik_2025_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2025_df['WAB'] = daily_torvik_2025_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2025_df['season'] = 2025\n",
    "daily_torvik_2025_df = daily_torvik_2025_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2025_df.columns = ['season','date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "assert len(set(daily_torvik_2021_df['team']) - set(team_map['team'])) == 0\n",
    "assert len(set(daily_torvik_2022_df['team']) - set(team_map['team'])) == 0\n",
    "assert len(set(daily_torvik_2023_df['team']) - set(team_map['team'])) == 0\n",
    "assert len(set(daily_torvik_2024_df['team']) - set(team_map['team'])) == 0\n",
    "assert len(set(daily_torvik_2025_df['team']) - set(team_map['team'])) == 0\n",
    "\n",
    "daily_torvik_df = pd.concat([daily_torvik_2021_df, daily_torvik_2022_df, daily_torvik_2023_df, daily_torvik_2024_df, daily_torvik_2025_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- unify date dtype to Int64 on both frames ---\n",
    "import re\n",
    "game_df['date_key'] = pd.to_numeric(game_df['date'], errors='coerce').astype('Int64')\n",
    "daily_torvik_df['date_key'] = pd.to_numeric(daily_torvik_df['date'], errors='coerce').astype('Int64')\n",
    "\n",
    "# --- normalize team names (strip seeds/suffixes) ---\n",
    "name_pat = r'^([A-Za-z\\s.&\\'-]+)'\n",
    "def clean_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    m = re.match(name_pat, str(s))\n",
    "    base = m.group(1) if m else str(s)\n",
    "    return re.sub(r'\\s+', ' ', base).strip()\n",
    "\n",
    "game_df['home_key'] = game_df['home'].map(clean_team)\n",
    "game_df['away_key'] = game_df['away'].map(clean_team)\n",
    "daily_torvik_df['team_key'] = daily_torvik_df['team'].map(clean_team)\n",
    "\n",
    "right = daily_torvik_df.drop_duplicates(['date_key', 'team_key']).copy()\n",
    "\n",
    "# --- Build HOME version of the right table ---\n",
    "home_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_home = right.rename(columns={'team_key': 'home_key', **{c: f'{c}_home' for c in home_cols}})\n",
    "\n",
    "# --- Merge HOME ---\n",
    "merged_df = game_df.merge(\n",
    "    torvik_home,\n",
    "    on=['date_key', 'home_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# --- Build AWAY version of the right table ---\n",
    "away_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_away = right.rename(columns={'team_key': 'away_key', **{c: f'{c}_away' for c in away_cols}})\n",
    "\n",
    "# --- Merge AWAY ---\n",
    "merged_df = merged_df.merge(\n",
    "    torvik_away,\n",
    "    on=['date_key', 'away_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "merged_df['season'] = merged_df['season_home']\n",
    "merged_df['neutral_site'] = np.where(merged_df['neutral_site'] == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[[\n",
    "    'game_id',\n",
    "    'season',\n",
    "    'date',\n",
    "    'date_utc',\n",
    "    'time_utc',\n",
    "    'neutral_site',\n",
    "    'home',\n",
    "    'away',\n",
    "    'home_1h',\n",
    "    'away_1h',\n",
    "    'home_2h',\n",
    "    'away_2h',\n",
    "    'home_score',\n",
    "    'away_score',\n",
    "    'home_margin',\n",
    "    'away_margin',\n",
    "    'assists_home',\n",
    "    'fouls_home',\n",
    "    'technicalFouls_home',\n",
    "    'flagrantFouls_home',\n",
    "    'totalRebounds_home',\n",
    "    'offensiveRebounds_home',\n",
    "    'defensiveRebounds_home',\n",
    "    'pointsInPaint_home',\n",
    "    'turnovers_home',\n",
    "    'turnoverPoints_home',\n",
    "    'steals_home',\n",
    "    'blocks_home',\n",
    "    'fastBreakPoints_home',\n",
    "    'assists_away',\n",
    "    'fouls_away',\n",
    "    'technicalFouls_away',\n",
    "    'flagrantFouls_away',\n",
    "    'totalRebounds_away',\n",
    "    'offensiveRebounds_away',\n",
    "    'defensiveRebounds_away',\n",
    "    'pointsInPaint_away',\n",
    "    'turnovers_away',\n",
    "    'turnoverPoints_away',\n",
    "    'steals_away',\n",
    "    'blocks_away',\n",
    "    'fastBreakPoints_away',\n",
    "    'official_1',\n",
    "    'official_2',\n",
    "    'official_3',  \n",
    "    'rank_home',\n",
    "    'conf_home',\n",
    "    'games_home',\n",
    "    'adj_off_eff_home',\n",
    "    'adj_def_eff_home',\n",
    "    'barthag_home',\n",
    "    'efg_pct_home',\n",
    "    'efgd_pct_home',\n",
    "    'tor_home',\n",
    "    'tord_home',\n",
    "    'orb_home',\n",
    "    'drb_home',\n",
    "    'ftr_home',\n",
    "    'ftrd_home',\n",
    "    'two_pt_pct_home',\n",
    "    'two_pt_def_pct_home',\n",
    "    'three_pt_pct_home',\n",
    "    'three_pt_def_pct_home',\n",
    "    'three_pt_rt_home',\n",
    "    'three_pt_def_rt_home',\n",
    "    'adj_tempo_home',\n",
    "    'wab_home',\n",
    "    'rank_away',\n",
    "    'conf_away',\n",
    "    'games_away',\n",
    "    'adj_off_eff_away',\n",
    "    'adj_def_eff_away',\n",
    "    'barthag_away',\n",
    "    'efg_pct_away',\n",
    "    'efgd_pct_away',\n",
    "    'tor_away',\n",
    "    'tord_away',\n",
    "    'orb_away',\n",
    "    'drb_away',\n",
    "    'ftr_away',\n",
    "    'ftrd_away',\n",
    "    'two_pt_pct_away',\n",
    "    'two_pt_def_pct_away',\n",
    "    'three_pt_pct_away',\n",
    "    'three_pt_def_pct_away',\n",
    "    'three_pt_rt_away',\n",
    "    'three_pt_def_rt_away',\n",
    "    'adj_tempo_away',\n",
    "    'wab_away']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del daily_torvik_2021_df\n",
    "del daily_torvik_2022_df\n",
    "del daily_torvik_2023_df\n",
    "del daily_torvik_2024_df\n",
    "del daily_torvik_2025_df\n",
    "del torvik_away\n",
    "del torvik_home\n",
    "del game_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df = merged_df[[\n",
    "    \"game_id\",\n",
    "    'home_1h',\n",
    "    'away_1h',\n",
    "    'home_2h',\n",
    "    'away_2h',\n",
    "    'home_score',\n",
    "    'away_score',\n",
    "    'home_margin',\n",
    "    'away_margin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Optional, Iterable\n",
    "\n",
    "OFFICIAL_COLS = ['official_1', 'official_2', 'official_3']\n",
    "CONF_COLS = ['conf_home', 'conf_away']\n",
    "LOCAL_TZ = 'America/New_York'\n",
    "\n",
    "def _ensure_date_key_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize YYYYMMDD to 8-char string.\"\"\"\n",
    "    return s.astype(str).str.extract(r'(\\d{8})')[0]\n",
    "\n",
    "def _build_tipoff_utc(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build timezone-aware UTC datetime from (date_key + time_utc like '21:00Z').\n",
    "    Requires: 'date_key' (YYYYMMDD) and 'time_utc' ('HH:MMZ' or 'HH:MM').\n",
    "    \"\"\"\n",
    "    if 'date_key' not in df.columns:\n",
    "        raise KeyError(\"Expected 'date_key' (YYYYMMDD).\")\n",
    "    if 'time_utc' not in df.columns:\n",
    "        raise KeyError(\"Expected 'time_utc' like '21:00Z' or '21:00'.\")\n",
    "\n",
    "    date_key = _ensure_date_key_str(df['date'])\n",
    "    t = df['time_utc'].astype(str).str.strip()\n",
    "    t = np.where(t.str.endswith('Z'), t, t + 'Z')  # ensure trailing Z\n",
    "    iso = pd.to_datetime(date_key, format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d') + ' ' + t\n",
    "    tipoff_utc = pd.to_datetime(iso, utc=True, errors='coerce', infer_datetime_format=True)\n",
    "    return tipoff_utc\n",
    "\n",
    "def _time_features_from_dt(dt: pd.Series, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From a timezone-aware datetime series, produce:\n",
    "      - {prefix}_hour, {prefix}_minute, {prefix}_second\n",
    "      - {prefix}_seconds_since_midnight\n",
    "      - {prefix}_hour_sin, {prefix}_hour_cos (cyclical)\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=dt.index)\n",
    "    out[f'{prefix}_hour'] = dt.dt.hour.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_minute'] = dt.dt.minute.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_second'] = dt.dt.second.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_seconds_since_midnight'] = (\n",
    "        out[f'{prefix}_hour'] * 3600 + out[f'{prefix}_minute'] * 60 + out[f'{prefix}_second']\n",
    "    ).astype('int32')\n",
    "\n",
    "    two_pi = 2 * np.pi\n",
    "    out[f'{prefix}_hour_sin'] = np.sin(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    out[f'{prefix}_hour_cos'] = np.cos(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    return out\n",
    "\n",
    "def _add_day_flags(local_dt: pd.Series, base_df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Day-of-week flags on LOCAL time:\n",
    "      - {prefix}_is_weekend (Sat/Sun)\n",
    "      - {prefix}_is_primetime (18:00–22:59)\n",
    "      - {prefix}_daypart_* one-hots: morning(5–11), afternoon(12–16), evening(17–21), late(other)\n",
    "    \"\"\"\n",
    "    out = base_df.copy()\n",
    "    dow = local_dt.dt.dayofweek  # Mon=0..Sun=6\n",
    "    out[f'{prefix}_is_weekend'] = dow.isin([5, 6]).fillna(False).astype('int8')\n",
    "\n",
    "    hour = local_dt.dt.hour.fillna(0).astype(int)\n",
    "    out[f'{prefix}_is_primetime'] = ((hour >= 18) & (hour <= 22)).astype('int8')\n",
    "\n",
    "    def daypart(h):\n",
    "        if 5 <= h <= 11:  return 'morning'\n",
    "        if 12 <= h <= 16: return 'afternoon'\n",
    "        if 17 <= h <= 21: return 'evening'\n",
    "        return 'late'\n",
    "\n",
    "    dp = hour.map(daypart).astype('category')\n",
    "    dummies = pd.get_dummies(dp, prefix=f'{prefix}_daypart', dtype='int8')\n",
    "    out = pd.concat([out, dummies], axis=1)\n",
    "    return out\n",
    "\n",
    "# ---------- Officials: shared encoding across all slots ----------\n",
    "def fit_official_encoder(df: pd.DataFrame, official_cols: Iterable[str] = OFFICIAL_COLS) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Fit a single shared encoding for officials across all official columns.\n",
    "    Reserve 0 for 'UNK' (missing/unknown).\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for c in official_cols:\n",
    "        if c in df.columns:\n",
    "            vals.append(df[c].astype('string'))\n",
    "    if not vals:\n",
    "        return {'UNK': 0}\n",
    "    all_offs = pd.concat(vals, axis=0).dropna()\n",
    "    uniq = sorted(all_offs.unique())\n",
    "    mapping = {'UNK': 0}\n",
    "    mapping.update({name: i + 1 for i, name in enumerate(uniq)})\n",
    "    return mapping\n",
    "\n",
    "def transform_officials_with_map(df: pd.DataFrame, mapping: Dict[str, int],\n",
    "                                 official_cols: Iterable[str] = OFFICIAL_COLS) -> pd.DataFrame:\n",
    "    \"\"\"Apply the shared mapping to each official* column, creating *_code columns.\"\"\"\n",
    "    out = df.copy()\n",
    "    unk = mapping.get('UNK', 0)\n",
    "    for c in official_cols:\n",
    "        if c in out.columns:\n",
    "            s = out[c].astype('string')\n",
    "            out[f'{c}_code'] = s.map(mapping).fillna(unk).astype('int32')\n",
    "        else:\n",
    "            out[f'{c}_code'] = unk\n",
    "    return out\n",
    "\n",
    "# ---------- Conference encoders ----------\n",
    "def fit_label_encoder(series: pd.Series, fill_value: str = 'UNK') -> Dict[str, int]:\n",
    "    \"\"\"Simple label encoder fit: reserve 0 for UNK.\"\"\"\n",
    "    s = series.astype('string').fillna(fill_value)\n",
    "    uniq = sorted(s.unique())\n",
    "    mapping = {fill_value: 0}\n",
    "    # start real categories at 1, ensure UNK remains 0 even if present in uniques\n",
    "    idx = 1\n",
    "    for val in uniq:\n",
    "        if val == fill_value:\n",
    "            continue\n",
    "        mapping[val] = idx\n",
    "        idx += 1\n",
    "    return mapping\n",
    "\n",
    "def transform_with_map(series: pd.Series, mapping: Dict[str, int], fill_value: str = 'UNK') -> pd.Series:\n",
    "    \"\"\"Transform using a prefit mapping, unknowns go to 0.\"\"\"\n",
    "    return series.astype('string').fillna(fill_value).map(mapping).fillna(mapping.get(fill_value, 0)).astype('int32')\n",
    "\n",
    "# ------------------ PUBLIC ENTRY ------------------\n",
    "def build_time_officials_conference_features(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    add_et_features: bool = True,\n",
    "    make_conference_dummies: bool = False,\n",
    "    official_map: Optional[Dict[str, int]] = None,\n",
    "    conf_home_map: Optional[Dict[str, int]] = None,\n",
    "    conf_away_map: Optional[Dict[str, int]] = None,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, int]]]:\n",
    "    \"\"\"\n",
    "    STEP 1: Add time features + encode officials (shared) + encode conferences.\n",
    "\n",
    "    Fit/transform behavior:\n",
    "      - If official_map / conf_*_map are provided, they are USED to transform (no refit).\n",
    "      - If not provided, maps are FIT on the given df (OK for quick experiments; for strict ML practice,\n",
    "        fit on TRAIN ONLY and pass the maps for VAL/TEST to avoid distribution drift).\n",
    "\n",
    "    Returns:\n",
    "      features_1 (DataFrame), enc_maps (dict with 'official_map','conference_home_map','conference_away_map')\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # --- Compose UTC datetime from date_key + time_utc, then add UTC features ---\n",
    "    out['date_key'] = _ensure_date_key_str(out['date'])\n",
    "    out['tipoff_utc'] = _build_tipoff_utc(out)\n",
    "    utc_feats = _time_features_from_dt(out['tipoff_utc'], prefix='utc')\n",
    "    out = pd.concat([out, utc_feats], axis=1)\n",
    "\n",
    "    # --- ET (local) features + day flags ---\n",
    "    if add_et_features:\n",
    "        tipoff_et = out['tipoff_utc'].dt.tz_convert(LOCAL_TZ)\n",
    "        et_feats = _time_features_from_dt(tipoff_et, prefix='et')\n",
    "        out = pd.concat([out, et_feats], axis=1)\n",
    "        out = _add_day_flags(tipoff_et, out, prefix='et')\n",
    "\n",
    "    enc_maps: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "    # --- Officials (shared encoding across official1/2/3) ---\n",
    "    if official_map is None:\n",
    "        official_map = fit_official_encoder(out, OFFICIAL_COLS)\n",
    "    out = transform_officials_with_map(out, official_map, OFFICIAL_COLS)\n",
    "    enc_maps['official_map'] = official_map\n",
    "\n",
    "    # --- Conferences (label encodings, separate maps for home/away) ---\n",
    "    if 'conf_home' in out.columns:\n",
    "        if conf_home_map is None:\n",
    "            conf_home_map = fit_label_encoder(out['conf_home'])\n",
    "        out['conf_home_code'] = transform_with_map(out['conf_home'], conf_home_map)\n",
    "        enc_maps['conf_home_map'] = conf_home_map\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_home'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_home', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    if 'conf_away' in out.columns:\n",
    "        if conf_away_map is None:\n",
    "            conf_away_map = fit_label_encoder(out['conf_away'])\n",
    "        out['conf_away_code'] = transform_with_map(out['conf_away'], conf_away_map)\n",
    "        enc_maps['conf_away_map'] = conf_away_map\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_away'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_away', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    return out, enc_maps\n",
    "\n",
    "features_1, enc_maps = build_time_officials_conference_features(\n",
    "        merged_df,\n",
    "        add_et_features=True,\n",
    "        make_conference_dummies=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = features_1[['game_id', \"neutral_site\", 'utc_seconds_since_midnight', 'utc_hour_sin', 'utc_hour_cos',\n",
    "       'et_hour', 'et_minute', 'et_second', 'et_seconds_since_midnight',\n",
    "       'et_hour_sin', 'et_hour_cos', 'et_is_weekend', 'et_is_primetime',\n",
    "       'et_daypart_afternoon', 'et_daypart_evening', 'et_daypart_late',\n",
    "       'et_daypart_morning', 'official_1_code', 'official_2_code',\n",
    "       'official_3_code', 'conf_home_code', 'conf_away_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['game_id', 'season', 'date', 'date_utc', 'time_utc', 'neutral_site',\n",
       "       'home', 'away', 'home_1h', 'away_1h', 'home_2h', 'away_2h',\n",
       "       'home_score', 'away_score', 'home_margin', 'away_margin',\n",
       "       'assists_home', 'fouls_home', 'technicalFouls_home',\n",
       "       'flagrantFouls_home', 'totalRebounds_home', 'offensiveRebounds_home',\n",
       "       'defensiveRebounds_home', 'pointsInPaint_home', 'turnovers_home',\n",
       "       'turnoverPoints_home', 'steals_home', 'blocks_home',\n",
       "       'fastBreakPoints_home', 'assists_away', 'fouls_away',\n",
       "       'technicalFouls_away', 'flagrantFouls_away', 'totalRebounds_away',\n",
       "       'offensiveRebounds_away', 'defensiveRebounds_away',\n",
       "       'pointsInPaint_away', 'turnovers_away', 'turnoverPoints_away',\n",
       "       'steals_away', 'blocks_away', 'fastBreakPoints_away', 'official_1',\n",
       "       'official_2', 'official_3', 'rank_home', 'conf_home', 'games_home',\n",
       "       'adj_off_eff_home', 'adj_def_eff_home', 'barthag_home', 'efg_pct_home',\n",
       "       'efgd_pct_home', 'tor_home', 'tord_home', 'orb_home', 'drb_home',\n",
       "       'ftr_home', 'ftrd_home', 'two_pt_pct_home', 'two_pt_def_pct_home',\n",
       "       'three_pt_pct_home', 'three_pt_def_pct_home', 'three_pt_rt_home',\n",
       "       'three_pt_def_rt_home', 'adj_tempo_home', 'wab_home', 'rank_away',\n",
       "       'conf_away', 'games_away', 'adj_off_eff_away', 'adj_def_eff_away',\n",
       "       'barthag_away', 'efg_pct_away', 'efgd_pct_away', 'tor_away',\n",
       "       'tord_away', 'orb_away', 'drb_away', 'ftr_away', 'ftrd_away',\n",
       "       'two_pt_pct_away', 'two_pt_def_pct_away', 'three_pt_pct_away',\n",
       "       'three_pt_def_pct_away', 'three_pt_rt_away', 'three_pt_def_rt_away',\n",
       "       'adj_tempo_away', 'wab_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03eca27aa3e5b0c2bf98348f6751bc7dc08663828d24c367008019d5f5934307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
