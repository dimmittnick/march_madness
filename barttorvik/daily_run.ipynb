{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAILY GAME IDS\n",
    "\n",
    "- grabs games based on date\n",
    "- date, time, home, away, neutral, conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "DATE = \"20251107\"\n",
    "csv_files = glob.glob(\"data/boxscores/game-info-2026/*.csv\")\n",
    "combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "combined_df = combined_df.merge(team_map, left_on=\"home_team\", right_on=\"espn\", how=\"left\").merge(team_map, left_on=\"away_team\", right_on=\"espn\", how=\"left\")\n",
    "\n",
    "combined_df['home'] = combined_df['team_x']\n",
    "combined_df['away'] = combined_df['team_y']\n",
    "\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "combined_df['date_key'] = pd.to_numeric(combined_df['date'], errors='coerce').astype('Int64')\n",
    "\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "combined_df['date_key'] = pd.to_numeric(combined_df['date'], errors='coerce').astype('Int64')\n",
    "conferences = pd.concat([pd.read_csv(\"s3://collegebasketballinsiders/daily-torvik/2024/barttorvik_20240312.csv\")[[\"Team\", \"Conf\"]], pd.read_csv(\"s3://collegebasketballinsiders/daily-torvik/2025/barttorvik_20250318.csv\")[[\"Team\", \"Conf\"]], pd.read_csv(\"barttorvik_2026_all.csv\")[[\"Team\", \"Conf\"]]], axis=0)\n",
    "conferences = conferences[conferences['Team'] != \"Team\"]\n",
    "conferences['Team'] = conferences['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "conferences = conferences.drop_duplicates(subset=\"Team\")\n",
    "\n",
    "# --- normalize team names (strip seeds/suffixes) ---\n",
    "name_pat = r'^([A-Za-z\\s.&\\'-]+)'\n",
    "def clean_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    m = re.match(name_pat, str(s))\n",
    "    base = m.group(1) if m else str(s)\n",
    "    return re.sub(r'\\s+', ' ', base).strip()\n",
    "\n",
    "combined_df['home_key'] = combined_df['home'].map(clean_team)\n",
    "combined_df['away_key'] = combined_df['away'].map(clean_team)\n",
    "conferences['team_key'] = conferences['Team'].map(clean_team)\n",
    "\n",
    "right = conferences.drop_duplicates(['team_key']).copy()\n",
    "\n",
    "# --- Build HOME version of the right table ---\n",
    "home_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_home = right.rename(columns={'team_key': 'home_key', **{c: f'{c}_home' for c in home_cols}})\n",
    "\n",
    "# --- Merge HOME ---\n",
    "combined_df = combined_df.merge(\n",
    "    torvik_home,\n",
    "    on='home_key',\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# --- Build AWAY version of the right table ---\n",
    "away_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_away = right.rename(columns={'team_key': 'away_key', **{c: f'{c}_away' for c in away_cols}})\n",
    "\n",
    "# --- Merge AWAY ---\n",
    "combined_df = combined_df.merge(\n",
    "    torvik_away,\n",
    "    on='away_key',\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "combined_df['season'] = 2026\n",
    "combined_df['neutral_site'] = np.where(combined_df['neutral_site'] == True, 1, 0)\n",
    "\n",
    "combined_df = combined_df[[\"game_id\", \"date\", \"date_key\", \"date_utc\", \"time_utc\", \"neutral_site\", \"home\", \"away\", \"Conf_home\", \"Conf_away\"]]\n",
    "combined_df.columns = [\"game_id\", \"date\", \"date_key\", \"date_utc\", \"time_utc\", \"neutral_site\", \"home\", \"away\", \"conf_home\", \"conf_away\"]\n",
    "\n",
    "csv_files = glob.glob(f\"daily-box-score-ids/{DATE}/*.csv\")\n",
    "game_id_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "game_ids = list(game_id_df['game_id'])\n",
    "combined_df[combined_df['game_id'].isin(game_ids)].to_csv(\"daily-games/daily.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEASON GAME INFORMATION AND TEAM STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdimmitt/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/game-info-2026/*.csv\")\n",
    "combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "combined_df = combined_df.merge(team_map, left_on=\"home_team\", right_on=\"espn\", how=\"left\").merge(team_map, left_on=\"away_team\", right_on=\"espn\", how=\"left\")\n",
    "\n",
    "combined_df['home'] = combined_df['team_x']\n",
    "combined_df['away'] = combined_df['team_y']\n",
    "\n",
    "combined_df = combined_df.dropna(subset=\"home\").dropna(subset=\"away\").dropna(subset=\"home_1h\")\n",
    "combined_df = combined_df[['game_id', 'date_utc', 'time_utc', 'neutral_site', 'home',\n",
    "       'away', 'home_1h', 'away_1h', 'home_2h', 'away_2h', 'home_score',\n",
    "       'away_score']]\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/team-stats-2026/*.csv\")\n",
    "team_combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "combined_df.sort_values(\"date_utc\")\n",
    "\n",
    "df = team_combined_df.sort_values(['displayOrder'])\n",
    "\n",
    "# create a helper column to pair home/away rows by game id\n",
    "# (if you don't already have a game_id column)\n",
    "# Split into home and away\n",
    "home_df = df[df['homeAway'] == 'home'].copy()\n",
    "away_df = df[df['homeAway'] == 'away'].copy()\n",
    "\n",
    "# Columns we don't want duplicated (they’ll be renamed anyway)\n",
    "cols_to_remove = ['homeAway', 'displayOrder', 'abbreviation', 'team_id']\n",
    "\n",
    "# Rename columns to indicate home/away\n",
    "home_df = home_df.drop(columns=cols_to_remove).add_suffix('_home')\n",
    "away_df = away_df.drop(columns=cols_to_remove).add_suffix('_away')\n",
    "\n",
    "# Merge back together on the shared game_id\n",
    "# (keep original game_id)\n",
    "final_df = pd.merge(\n",
    "    home_df,\n",
    "    away_df,\n",
    "    left_on='game_id_home',\n",
    "    right_on='game_id_away',\n",
    "    suffixes=('', ''),\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Keep just one copy of game_id\n",
    "final_df['game_id'] = final_df['game_id_home']\n",
    "final_df = final_df.drop(columns=['game_id_home', 'game_id_away'])\n",
    "\n",
    "# Optional: reorder columns to have game_id first\n",
    "cols = ['game_id'] + [c for c in final_df.columns if c != 'game_id']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "final_df = final_df[['game_id', 'assists_home', 'defensiveRebounds_home', 'freeThrowPct_home',\n",
    "       'threePointFieldGoalsMade-threePointFieldGoalsAttempted_home',\n",
    "       'fouls_home', 'totalRebounds_home', 'threePointFieldGoalPct_home',\n",
    "       'teamTurnovers_home', 'pointsInPaint_home', 'technicalFouls_home',\n",
    "       'totalTechnicalFouls_home', 'largestLead_home',\n",
    "       'offensiveRebounds_home', 'fieldGoalPct_home',\n",
    "       'totalTurnovers_home', 'turnoverPoints_home', 'flagrantFouls_home',\n",
    "       'freeThrowsMade-freeThrowsAttempted_home', 'steals_home',\n",
    "       'fieldGoalsMade-fieldGoalsAttempted_home', 'blocks_home',\n",
    "       'fastBreakPoints_home', 'turnovers_home',  'assists_away',\n",
    "       'defensiveRebounds_away', 'freeThrowPct_away',\n",
    "       'threePointFieldGoalsMade-threePointFieldGoalsAttempted_away',\n",
    "       'fouls_away', 'totalRebounds_away', 'threePointFieldGoalPct_away',\n",
    "       'teamTurnovers_away', 'pointsInPaint_away', 'technicalFouls_away',\n",
    "       'totalTechnicalFouls_away', 'largestLead_away',\n",
    "       'offensiveRebounds_away', 'fieldGoalPct_away',\n",
    "       'totalTurnovers_away', 'turnoverPoints_away', 'flagrantFouls_away',\n",
    "       'freeThrowsMade-freeThrowsAttempted_away', 'steals_away',\n",
    "       'fieldGoalsMade-fieldGoalsAttempted_away', 'blocks_away',\n",
    "       'fastBreakPoints_away', 'turnovers_away']]\n",
    "\n",
    "combined_df = combined_df.merge(final_df, on=\"game_id\")\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/officials-2026/*.csv\")\n",
    "officials_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# create a rank/order number per game_id\n",
    "officials_df['official_number'] = officials_df.groupby('game_id').cumcount() + 1\n",
    "\n",
    "# pivot to wide format\n",
    "flat_officials = (\n",
    "    officials_df.pivot(index='game_id', columns='official_number', values='official_name')\n",
    "    .rename(columns=lambda x: f'official_{x}')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "flat_officials = flat_officials[[\"game_id\", \"official_1\", \"official_2\", \"official_3\"]]\n",
    "\n",
    "combined_df = combined_df.merge(flat_officials, on=\"game_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "game_df = combined_df\n",
    "game_df['date'] = pd.to_datetime(game_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "game_df['home_margin'] = game_df['home_score'] - game_df['away_score']\n",
    "game_df['away_margin'] = game_df['away_score'] - game_df['home_score']\n",
    "\n",
    "csv_files_2026 = glob.glob(\"daily_csvs_2026/*.csv\")\n",
    "daily_torvik_2026_df = pd.concat((pd.read_csv(f) for f in csv_files_2026), ignore_index=True)\n",
    "daily_torvik_2026_df = daily_torvik_2026_df[daily_torvik_2026_df['Team'] != \"Team\"]\n",
    "daily_torvik_2026_df['Team'] = daily_torvik_2026_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2026_df['WAB'] = daily_torvik_2026_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2026_df['season'] = 2026\n",
    "daily_torvik_2026_df = daily_torvik_2026_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2026_df.columns = ['season', 'date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "# assert len(set(daily_torvik_2026_df['team']) - set(team_map['team'])) == 0\n",
    "\n",
    "daily_torvik_df = daily_torvik_2026_df\n",
    "\n",
    "\n",
    "import re\n",
    "game_df['date_key'] = pd.to_numeric(game_df['date'], errors='coerce').astype('Int64')\n",
    "daily_torvik_df['date_key'] = pd.to_numeric(daily_torvik_df['date'], errors='coerce').astype('Int64')\n",
    "\n",
    "# --- normalize team names (strip seeds/suffixes) ---\n",
    "name_pat = r'^([A-Za-z\\s.&\\'-]+)'\n",
    "def clean_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    m = re.match(name_pat, str(s))\n",
    "    base = m.group(1) if m else str(s)\n",
    "    return re.sub(r'\\s+', ' ', base).strip()\n",
    "\n",
    "game_df['home_key'] = game_df['home'].map(clean_team)\n",
    "game_df['away_key'] = game_df['away'].map(clean_team)\n",
    "daily_torvik_df['team_key'] = daily_torvik_df['team'].map(clean_team)\n",
    "\n",
    "right = daily_torvik_df.drop_duplicates(['date_key', 'team_key']).copy()\n",
    "\n",
    "# --- Build HOME version of the right table ---\n",
    "home_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_home = right.rename(columns={'team_key': 'home_key', **{c: f'{c}_home' for c in home_cols}})\n",
    "\n",
    "# --- Merge HOME ---\n",
    "merged_df = game_df.merge(\n",
    "    torvik_home,\n",
    "    on=['date_key', 'home_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# --- Build AWAY version of the right table ---\n",
    "away_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_away = right.rename(columns={'team_key': 'away_key', **{c: f'{c}_away' for c in away_cols}})\n",
    "\n",
    "# --- Merge AWAY ---\n",
    "merged_df = merged_df.merge(\n",
    "    torvik_away,\n",
    "    on=['date_key', 'away_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "merged_df['season'] = 2026\n",
    "merged_df['neutral_site'] = np.where(merged_df['neutral_site'] == True, 1, 0)\n",
    "\n",
    "merged_df = merged_df[[\n",
    "    'game_id',\n",
    "    'season',\n",
    "    'date',\n",
    "    'date_utc',\n",
    "    'time_utc',\n",
    "    'neutral_site',\n",
    "    'home',\n",
    "    'away',\n",
    "    'home_1h',\n",
    "    'away_1h',\n",
    "    'home_2h',\n",
    "    'away_2h',\n",
    "    'home_score',\n",
    "    'away_score',\n",
    "    'home_margin',\n",
    "    'away_margin',\n",
    "    'assists_home',\n",
    "    'fouls_home',\n",
    "    'technicalFouls_home',\n",
    "    'flagrantFouls_home',\n",
    "    'totalRebounds_home',\n",
    "    'offensiveRebounds_home',\n",
    "    'defensiveRebounds_home',\n",
    "    'pointsInPaint_home',\n",
    "    'turnovers_home',\n",
    "    'turnoverPoints_home',\n",
    "    'steals_home',\n",
    "    'blocks_home',\n",
    "    'fastBreakPoints_home',\n",
    "    'assists_away',\n",
    "    'fouls_away',\n",
    "    'technicalFouls_away',\n",
    "    'flagrantFouls_away',\n",
    "    'totalRebounds_away',\n",
    "    'offensiveRebounds_away',\n",
    "    'defensiveRebounds_away',\n",
    "    'pointsInPaint_away',\n",
    "    'turnovers_away',\n",
    "    'turnoverPoints_away',\n",
    "    'steals_away',\n",
    "    'blocks_away',\n",
    "    'fastBreakPoints_away',\n",
    "    'official_1',\n",
    "    'official_2',\n",
    "    'official_3',  \n",
    "    'rank_home',\n",
    "    'conf_home',\n",
    "    'games_home',\n",
    "    'adj_off_eff_home',\n",
    "    'adj_def_eff_home',\n",
    "    'barthag_home',\n",
    "    'efg_pct_home',\n",
    "    'efgd_pct_home',\n",
    "    'tor_home',\n",
    "    'tord_home',\n",
    "    'orb_home',\n",
    "    'drb_home',\n",
    "    'ftr_home',\n",
    "    'ftrd_home',\n",
    "    'two_pt_pct_home',\n",
    "    'two_pt_def_pct_home',\n",
    "    'three_pt_pct_home',\n",
    "    'three_pt_def_pct_home',\n",
    "    'three_pt_rt_home',\n",
    "    'three_pt_def_rt_home',\n",
    "    'adj_tempo_home',\n",
    "    'wab_home',\n",
    "    'rank_away',\n",
    "    'conf_away',\n",
    "    'games_away',\n",
    "    'adj_off_eff_away',\n",
    "    'adj_def_eff_away',\n",
    "    'barthag_away',\n",
    "    'efg_pct_away',\n",
    "    'efgd_pct_away',\n",
    "    'tor_away',\n",
    "    'tord_away',\n",
    "    'orb_away',\n",
    "    'drb_away',\n",
    "    'ftr_away',\n",
    "    'ftrd_away',\n",
    "    'two_pt_pct_away',\n",
    "    'two_pt_def_pct_away',\n",
    "    'three_pt_pct_away',\n",
    "    'three_pt_def_pct_away',\n",
    "    'three_pt_rt_away',\n",
    "    'three_pt_def_rt_away',\n",
    "    'adj_tempo_away',\n",
    "    'wab_away']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SET 1 USING DAILY.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_time_officials_conference.py\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from typing import Dict, Optional, Iterable, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Configuration ----\n",
    "OFFICIAL_COLS = ['official_1', 'official_2', 'official_3']\n",
    "LOCAL_TZ = 'America/New_York'  # Eastern time\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _ensure_date_key_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize YYYYMMDD to 8-char string from any input series.\"\"\"\n",
    "    return s.astype(str).str.extract(r'(\\d{8})')[0]\n",
    "\n",
    "def _build_tipoff_utc(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build timezone-aware UTC datetime from (date_key + time_utc like '21:00Z').\n",
    "    Requires: 'date_key' (YYYYMMDD) and 'time_utc' ('HH:MMZ' or 'HH:MM').\n",
    "    \"\"\"\n",
    "    if 'date_utc' not in df.columns:\n",
    "        raise KeyError(\"Expected 'date_key' (YYYYMMDD).\")\n",
    "    if 'time_utc' not in df.columns:\n",
    "        raise KeyError(\"Expected 'time_utc' like '21:00Z' or '21:00'.\")\n",
    "\n",
    "    # use date_key (not 'date'); coerce invalids to NaT\n",
    "    date_key = _ensure_date_key_str(df['date'])\n",
    "    t = df['time_utc'].astype(str).str.strip()\n",
    "    t = np.where(t.str.endswith('Z'), t, t + 'Z')  # ensure trailing Z\n",
    "    iso_date = pd.to_datetime(date_key, format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    iso = iso_date + ' ' + t\n",
    "    tipoff_utc = pd.to_datetime(iso, utc=True, errors='coerce', infer_datetime_format=True)\n",
    "    return tipoff_utc\n",
    "\n",
    "def _time_features_from_dt(dt: pd.Series, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From a timezone-aware datetime series, produce:\n",
    "      - {prefix}_hour, {prefix}_minute, {prefix}_second\n",
    "      - {prefix}_seconds_since_midnight\n",
    "      - {prefix}_hour_sin, {prefix}_hour_cos (cyclical)\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=dt.index)\n",
    "    out[f'{prefix}_hour'] = dt.dt.hour.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_minute'] = dt.dt.minute.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_second'] = dt.dt.second.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_seconds_since_midnight'] = (\n",
    "        out[f'{prefix}_hour'] * 3600 + out[f'{prefix}_minute'] * 60 + out[f'{prefix}_second']\n",
    "    ).astype('int32')\n",
    "\n",
    "    two_pi = 2 * np.pi\n",
    "    out[f'{prefix}_hour_sin'] = np.sin(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    out[f'{prefix}_hour_cos'] = np.cos(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    return out\n",
    "\n",
    "def _add_day_flags(local_dt: pd.Series, base_df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Day-of-week flags on LOCAL time:\n",
    "      - {prefix}_is_weekend (Sat/Sun)\n",
    "      - {prefix}_is_primetime (18:00–22:59)\n",
    "      - {prefix}_daypart_* one-hots: morning(5–11), afternoon(12–16), evening(17–21), late(other)\n",
    "    \"\"\"\n",
    "    out = base_df.copy()\n",
    "    dow = local_dt.dt.dayofweek  # Mon=0..Sun=6\n",
    "    out[f'{prefix}_is_weekend'] = dow.isin([5, 6]).fillna(False).astype('int8')\n",
    "\n",
    "    hour = local_dt.dt.hour.fillna(0).astype(int)\n",
    "    out[f'{prefix}_is_primetime'] = ((hour >= 18) & (hour <= 22)).astype('int8')\n",
    "\n",
    "    def _daypart(h):\n",
    "        if 5 <= h <= 11:  return 'morning'\n",
    "        if 12 <= h <= 16: return 'afternoon'\n",
    "        if 17 <= h <= 21: return 'evening'\n",
    "        return 'late'\n",
    "\n",
    "    dp = hour.map(_daypart).astype('category')\n",
    "    dummies = pd.get_dummies(dp, prefix=f'{prefix}_daypart', dtype='int8')\n",
    "    out = pd.concat([out, dummies], axis=1)\n",
    "    return out\n",
    "\n",
    "# ---------- Transform (apply saved maps) ----------\n",
    "def transform_officials_with_map(df: pd.DataFrame, mapping: Dict[str, int],\n",
    "                                 official_cols: Iterable[str] = OFFICIAL_COLS) -> pd.DataFrame:\n",
    "    \"\"\"Apply the shared mapping to each official* column, creating *_code columns.\"\"\"\n",
    "    out = df.copy()\n",
    "    unk = mapping.get('UNK', 0)\n",
    "    for c in official_cols:\n",
    "        if c in out.columns:\n",
    "            s = out[c].astype('string')\n",
    "            out[f'{c}_code'] = s.map(mapping).fillna(unk).astype('int32')\n",
    "        else:\n",
    "            out[f'{c}_code'] = unk\n",
    "    return out\n",
    "\n",
    "def transform_with_map(series: pd.Series, mapping: Dict[str, int], fill_value: str = 'UNK') -> pd.Series:\n",
    "    \"\"\"Transform using a prefit mapping, unknowns go to code for fill_value (default 0).\"\"\"\n",
    "    return series.astype('string').fillna(fill_value).map(mapping).fillna(mapping.get(fill_value, 0)).astype('int32')\n",
    "\n",
    "# ---------- Public Inference Entry ----------\n",
    "def load_enc_maps(path: str) -> Dict[str, Dict[str, int]]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_time_officials_conference_features_inference(\n",
    "    df: pd.DataFrame,\n",
    "    enc_maps: Dict[str, Dict[str, int]],\n",
    "    *,\n",
    "    add_et_features: bool = True,\n",
    "    make_conference_dummies: bool = False\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, int]]]:\n",
    "    \"\"\"\n",
    "    INFERENCE version:\n",
    "      - Uses prefit maps in `enc_maps` to transform officials + conferences\n",
    "      - Builds UTC/ET time features + flags\n",
    "      - Does NOT refit any encoder\n",
    "    Returns: (features_df, enc_maps) for convenience\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Ensure date_key exists for time parsing\n",
    "    if 'date_key' not in out.columns:\n",
    "        if 'date' in out.columns:\n",
    "            out['date_key'] = _ensure_date_key_str(out['date'])\n",
    "        else:\n",
    "            raise KeyError(\"Expected 'date' or 'date_key' in inference dataframe.\")\n",
    "\n",
    "    # Build UTC time + time features\n",
    "    out['tipoff_utc'] = _build_tipoff_utc(out)\n",
    "    utc_feats = _time_features_from_dt(out['tipoff_utc'], prefix='utc')\n",
    "    out = pd.concat([out, utc_feats], axis=1)\n",
    "\n",
    "    # Local (ET) features + day flags\n",
    "    if add_et_features:\n",
    "        tipoff_et = out['tipoff_utc'].dt.tz_convert(LOCAL_TZ)\n",
    "        et_feats = _time_features_from_dt(tipoff_et, prefix='et')\n",
    "        out = pd.concat([out, et_feats], axis=1)\n",
    "        out = _add_day_flags(tipoff_et, out, prefix='et')\n",
    "\n",
    "    # Officials (shared map)\n",
    "    official_map = enc_maps.get('official_map', {'UNK': 0})\n",
    "    out = transform_officials_with_map(out, official_map, OFFICIAL_COLS)\n",
    "\n",
    "    # Conferences\n",
    "    if 'conf_home' in out.columns:\n",
    "        conf_home_map = enc_maps.get('conf_home_map', {'UNK': 0})\n",
    "        out['conf_home_code'] = transform_with_map(out['conf_home'], conf_home_map)\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_home'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_home', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    if 'conf_away' in out.columns:\n",
    "        conf_away_map = enc_maps.get('conf_away_map', {'UNK': 0})\n",
    "        out['conf_away_code'] = transform_with_map(out['conf_away'], conf_away_map)\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_away'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_away', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    return out, enc_maps\n",
    "\n",
    "# ---------- Optional: align to training feature set ----------\n",
    "def align_to_training_features(df_features: pd.DataFrame, train_feature_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex to the exact training feature set:\n",
    "      - add any missing columns (filled with 0),\n",
    "      - drop any extra columns,\n",
    "      - keep the same ordering as training.\n",
    "    Ensures numeric dtype for all features.\n",
    "    \"\"\"\n",
    "    X = df_features.reindex(columns=train_feature_cols, fill_value=0)\n",
    "    for c in X.columns:\n",
    "        if not np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce').fillna(0)\n",
    "    return X\n",
    "\n",
    "enc_maps = load_enc_maps(\"data/train/enc_maps.json\")\n",
    "\n",
    "# 2) Apply to new games dataframe (must have: 'date' or 'date_key', and 'time_utc')\n",
    "features_1, _ = build_time_officials_conference_features_inference(\n",
    "    pd.read_csv(\"daily-games/daily.csv\"), enc_maps,\n",
    "    add_et_features=True,\n",
    "    make_conference_dummies=True\n",
    ")\n",
    "# features_1[[\"et_daypart_afternoon\",'et_daypart_morning']] = 0\n",
    "features_1 = features_1[['game_id', 'utc_seconds_since_midnight', 'utc_hour_sin', 'utc_hour_cos',\n",
    "       'et_hour', 'et_minute', 'et_second', 'et_seconds_since_midnight',\n",
    "       'et_hour_sin', 'et_hour_cos', 'et_is_weekend', 'et_is_primetime',\n",
    "       'et_daypart_afternoon', 'et_daypart_evening', 'et_daypart_late',\n",
    "       'et_daypart_morning', 'official_1_code', 'official_2_code',\n",
    "       'official_3_code', 'conf_home_code', 'conf_away_code']]\n",
    "\n",
    "\n",
    "\n",
    "assert len(set(list(features_1.columns)) - set(['game_id', 'utc_seconds_since_midnight', 'utc_hour_sin', 'utc_hour_cos',\n",
    "       'et_hour', 'et_minute', 'et_second', 'et_seconds_since_midnight',\n",
    "       'et_hour_sin', 'et_hour_cos', 'et_is_weekend', 'et_is_primetime',\n",
    "       'et_daypart_afternoon', 'et_daypart_evening', 'et_daypart_late',\n",
    "       'et_daypart_morning', 'official_1_code', 'official_2_code',\n",
    "       'official_3_code', 'conf_home_code', 'conf_away_code'])) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SET 2/3 USING 2026 GAME INFORMATION AND TORVVIK RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- base dataframe ---\n",
    "df = merged_df[['game_id', 'season', 'date', 'date_utc', 'time_utc',\n",
    "       'neutral_site', 'home', 'away', 'home_1h', 'away_1h', 'home_2h',\n",
    "       'away_2h', 'home_score', 'away_score', 'home_margin',\n",
    "       'away_margin','rank_home', 'games_home',\n",
    "       'adj_off_eff_home', 'adj_def_eff_home', 'barthag_home',\n",
    "       'efg_pct_home', 'efgd_pct_home', 'tor_home', 'tord_home',\n",
    "       'orb_home', 'drb_home', 'ftr_home', 'ftrd_home', 'two_pt_pct_home',\n",
    "       'two_pt_def_pct_home', 'three_pt_pct_home',\n",
    "       'three_pt_def_pct_home', 'three_pt_rt_home',\n",
    "       'three_pt_def_rt_home', 'adj_tempo_home', 'wab_home', 'rank_away',\n",
    "       'games_away', 'adj_off_eff_away', 'adj_def_eff_away',\n",
    "       'barthag_away', 'efg_pct_away', 'efgd_pct_away', 'tor_away',\n",
    "       'tord_away', 'orb_away', 'drb_away', 'ftr_away', 'ftrd_away',\n",
    "       'two_pt_pct_away', 'two_pt_def_pct_away', 'three_pt_pct_away',\n",
    "       'three_pt_def_pct_away', 'three_pt_rt_away',\n",
    "       'three_pt_def_rt_away', 'adj_tempo_away', 'wab_away']].copy()\n",
    "\n",
    "# --- 1) datetime for chronological sort (UTC preferred if available) ---\n",
    "if 'date_utc' in df.columns and df['date_utc'].notna().any():\n",
    "    if 'time_utc' in df.columns:\n",
    "        df['game_dt'] = pd.to_datetime(\n",
    "            df['date_utc'].astype(str).str.strip() + ' ' +\n",
    "            df['time_utc'].fillna('00:00:00').astype(str).str.strip(),\n",
    "            errors='coerce', utc=True\n",
    "        )\n",
    "    else:\n",
    "        df['game_dt'] = pd.to_datetime(df['date_utc'], errors='coerce', utc=True)\n",
    "else:\n",
    "    df['game_dt'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# --- 2) bases from *_home / *_away ---\n",
    "suffix_cols = [c for c in df.columns if c.endswith('_home') or c.endswith('_away')]\n",
    "bases = sorted({c.rsplit('_', 1)[0] for c in suffix_cols})\n",
    "\n",
    "# --- 3) map columns to team/opp perspective ---\n",
    "home_to_team = {f'{b}_home': b for b in bases}\n",
    "away_to_team = {f'{b}_away': b for b in bases}\n",
    "home_to_opp  = {f'{b}_away': f'opp_{b}' for b in bases}\n",
    "away_to_opp  = {f'{b}_home': f'opp_{b}' for b in bases}\n",
    "\n",
    "id_cols = ['game_id','season','date','game_dt','neutral_site']\n",
    "id_cols = [c for c in id_cols if c in df.columns]\n",
    "\n",
    "home_view = df[id_cols + ['home','away'] + suffix_cols].copy()\n",
    "home_view = home_view.rename(columns={'home':'team','away':'opponent'})\n",
    "home_view = home_view.rename(columns={**home_to_team, **home_to_opp})\n",
    "home_view['is_home'] = 1\n",
    "\n",
    "away_view = df[id_cols + ['home','away'] + suffix_cols].copy()\n",
    "away_view = away_view.rename(columns={'away':'team','home':'opponent'})\n",
    "away_view = away_view.rename(columns={**away_to_team, **away_to_opp})\n",
    "away_view['is_home'] = 0\n",
    "\n",
    "team_games = pd.concat([home_view, away_view], ignore_index=True, sort=False)\n",
    "team_games = team_games.sort_values(['team','season','game_dt','game_id'], ignore_index=True)\n",
    "\n",
    "# --- 4) coerce numeric fields used below ---\n",
    "def _to_num(s: pd.Series) -> pd.Series:\n",
    "    if s.dtype == 'O':\n",
    "        s = s.astype(str).str.strip().str.rstrip('%')\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "numeric_needed = set()\n",
    "for b in bases:\n",
    "    if b in team_games.columns: numeric_needed.add(b)\n",
    "    ob = f'opp_{b}'\n",
    "    if ob in team_games.columns: numeric_needed.add(ob)\n",
    "if 'opp_rank' in team_games.columns: numeric_needed.add('opp_rank')\n",
    "\n",
    "if numeric_needed:\n",
    "    team_games[list(numeric_needed)] = team_games[list(numeric_needed)].apply(_to_num)\n",
    "\n",
    "# --- 5) cumulative opponent rank (inclusive + \"pre\" if you still use it) ---\n",
    "if 'opp_rank' in team_games.columns:\n",
    "    g = team_games.groupby(['team','season'], dropna=False)['opp_rank']\n",
    "    team_games['opp_rank_cummean_incl'] = g.cumsum() / (g.cumcount() + 1)  # includes current\n",
    "    cs = g.cumsum()\n",
    "    cnt = g.cumcount()\n",
    "    team_games['opp_rank_cummean_pre'] = cs.shift(1) / cnt.replace(0, np.nan)  # prior-only\n",
    "\n",
    "# --- 6) take the latest played row per team-season ---\n",
    "latest = (\n",
    "    team_games\n",
    "    .sort_values(['team','season','game_dt','game_id'])\n",
    "    .groupby(['team','season'], as_index=False, sort=False)\n",
    "    .tail(1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- 7) rename CURRENT values to match training names (lag1_*) ---\n",
    "team_feature_cols = [c for c in bases if c in latest.columns]\n",
    "opp_feature_cols  = [f'opp_{b}' for b in bases if f'opp_{b}' in latest.columns]\n",
    "\n",
    "rename_map = {}\n",
    "for c in team_feature_cols:\n",
    "    rename_map[c] = f'lag1_{c}'\n",
    "for c in opp_feature_cols:\n",
    "    rename_map[c] = f'lag1_{c}'\n",
    "\n",
    "latest_renamed = latest.rename(columns=rename_map)\n",
    "\n",
    "# --- 8) build features_2 with the exact columns you listed ---\n",
    "wanted_cols = ['game_id','team','opponent',\n",
    "    'lag1_adj_def_eff','lag1_adj_off_eff','lag1_adj_tempo','lag1_barthag',\n",
    "    'lag1_drb','lag1_efg_pct','lag1_efgd_pct','lag1_ftr','lag1_ftrd',\n",
    "    'lag1_games','lag1_orb','lag1_rank','lag1_three_pt_def_pct',\n",
    "    'lag1_three_pt_def_rt','lag1_three_pt_pct','lag1_three_pt_rt',\n",
    "    'lag1_tor','lag1_tord','lag1_two_pt_def_pct','lag1_two_pt_pct','lag1_wab',\n",
    "    'lag1_opp_adj_def_eff','lag1_opp_adj_off_eff','lag1_opp_adj_tempo',\n",
    "    'lag1_opp_barthag','lag1_opp_drb','lag1_opp_efg_pct','lag1_opp_efgd_pct',\n",
    "    'lag1_opp_ftr','lag1_opp_ftrd','lag1_opp_games','lag1_opp_orb',\n",
    "    'lag1_opp_rank','lag1_opp_three_pt_def_pct','lag1_opp_three_pt_def_rt',\n",
    "    'lag1_opp_three_pt_pct','lag1_opp_three_pt_rt','lag1_opp_tor',\n",
    "    'lag1_opp_tord','lag1_opp_two_pt_def_pct','lag1_opp_two_pt_pct',\n",
    "    'lag1_opp_wab',\n",
    "    'opp_rank_cummean_incl','opp_rank_cummean_pre'\n",
    "]\n",
    "\n",
    "# keep only those that exist (some sources may lack a few)\n",
    "final_cols = [c for c in wanted_cols if c in latest_renamed.columns]\n",
    "features_2 = latest_renamed[final_cols].copy()\n",
    "assert len(set(list(features_2.columns)) - set(['game_id', 'team', 'opponent',\n",
    "       'lag1_adj_def_eff', 'lag1_adj_off_eff',\n",
    "       'lag1_adj_tempo', 'lag1_barthag', 'lag1_drb', 'lag1_efg_pct',\n",
    "       'lag1_efgd_pct', 'lag1_ftr', 'lag1_ftrd', 'lag1_games', 'lag1_orb',\n",
    "       'lag1_rank', 'lag1_three_pt_def_pct', 'lag1_three_pt_def_rt',\n",
    "       'lag1_three_pt_pct', 'lag1_three_pt_rt', 'lag1_tor', 'lag1_tord',\n",
    "       'lag1_two_pt_def_pct', 'lag1_two_pt_pct', 'lag1_wab',\n",
    "       'lag1_opp_adj_def_eff', 'lag1_opp_adj_off_eff',\n",
    "       'lag1_opp_adj_tempo', 'lag1_opp_barthag', 'lag1_opp_drb',\n",
    "       'lag1_opp_efg_pct', 'lag1_opp_efgd_pct', 'lag1_opp_ftr',\n",
    "       'lag1_opp_ftrd', 'lag1_opp_games', 'lag1_opp_orb', 'lag1_opp_rank',\n",
    "       'lag1_opp_three_pt_def_pct', 'lag1_opp_three_pt_def_rt',\n",
    "       'lag1_opp_three_pt_pct', 'lag1_opp_three_pt_rt', 'lag1_opp_tor',\n",
    "       'lag1_opp_tord', 'lag1_opp_two_pt_def_pct', 'lag1_opp_two_pt_pct',\n",
    "       'lag1_opp_wab', 'opp_rank_cummean_incl', 'opp_rank_cummean_pre'])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_cbb_features_inference(raw_df, windows=(1,3,5,10), ewm_halflife=5, today_utc=None):\n",
    "    \"\"\"\n",
    "    Inference feature builder.\n",
    "\n",
    "    Only change from your previous version:\n",
    "      - Rest days:\n",
    "          * Historical per-game gaps (for rolling features) stay the same.\n",
    "          * The final 'rest_days' for the latest snapshot per team/season is\n",
    "            computed as (today_utc - last_completed_game_dt).days, so teams that\n",
    "            played a few days ago won't default to 7 anymore.\n",
    "\n",
    "    Args:\n",
    "        raw_df: wide game-level dataframe with *_home / *_away stats\n",
    "        windows: rolling windows\n",
    "        ewm_halflife: half-life for EWM\n",
    "        today_utc: pd.Timestamp (tz-aware, UTC). If None, uses current UTC time.\n",
    "    \"\"\"\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    # --- choose \"today\" in UTC (tz-aware) ---\n",
    "    if today_utc is None:\n",
    "        # use current UTC\n",
    "        today_utc = pd.Timestamp.utcnow()\n",
    "\n",
    "    # --- 0) Build a proper datetime (UTC if you have date_utc/time_utc) ---\n",
    "    if 'date_utc' in df.columns and df['date_utc'].notna().any():\n",
    "        if 'time_utc' in df.columns:\n",
    "            df['game_dt'] = pd.to_datetime(\n",
    "                df['date_utc'].astype(str).str.strip() + ' ' +\n",
    "                df['time_utc'].fillna('00:00:00').astype(str).str.strip(),\n",
    "                errors='coerce', utc=True\n",
    "            )\n",
    "        else:\n",
    "            df['game_dt'] = pd.to_datetime(df['date_utc'], errors='coerce', utc=True)\n",
    "    else:\n",
    "        df['game_dt'] = pd.to_datetime(df.get('date', pd.NaT), errors='coerce')\n",
    "        # if naive, assume UTC\n",
    "        if df['game_dt'].dt.tz is None:\n",
    "            df['game_dt'] = df['game_dt'].dt.tz_localize('UTC')\n",
    "\n",
    "    # Keep a simple sortable date for later (optional)\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    else:\n",
    "        df['date'] = df['game_dt'].dt.tz_convert('UTC').dt.date\n",
    "\n",
    "    # --- 1) Identify base stat names (strip _home/_away) ---\n",
    "    def _base_names(columns):\n",
    "        bases = set()\n",
    "        for c in columns:\n",
    "            if c.endswith('_home'):\n",
    "                bases.add(c[:-5])\n",
    "            elif c.endswith('_away'):\n",
    "                bases.add(c[:-5])\n",
    "        return sorted(bases)\n",
    "\n",
    "    stat_bases = _base_names(df.columns)\n",
    "\n",
    "    # --- 2) Long-format: one row per team per game (home & away views) ---\n",
    "    def _make_team_rows(side):\n",
    "        assert side in ('home','away')\n",
    "        other = 'away' if side == 'home' else 'home'\n",
    "\n",
    "        # map base stat names to (team_col, opp_col) for this perspective\n",
    "        base_map = {}\n",
    "        for b in stat_bases:\n",
    "            team_col = f'{b}_{side}'\n",
    "            opp_col  = f'{b}_{other}'\n",
    "            if team_col in df.columns and opp_col in df.columns:\n",
    "                base_map[b] = (team_col, opp_col)\n",
    "\n",
    "        is_home_val = 1 if side == 'home' else 0\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            'game_id': df['game_id'],\n",
    "            'season' : df['season'],\n",
    "            'date'   : df['date'],\n",
    "            'game_dt': df['game_dt'],\n",
    "            'team'   : df[side],\n",
    "            'opponent': df[other],\n",
    "            'is_home': np.full(len(df), is_home_val, dtype=np.int8),\n",
    "        })\n",
    "\n",
    "        # standardize scores/margins\n",
    "        if f'{side}_score' in df.columns and f'{other}_score' in df.columns:\n",
    "            out['team_score'] = pd.to_numeric(df[f'{side}_score'], errors='coerce')\n",
    "            out['opp_score']  = pd.to_numeric(df[f'{other}_score'], errors='coerce')\n",
    "\n",
    "        if f'{side}_margin' in df.columns and f'{other}_margin' in df.columns:\n",
    "            out['team_margin'] = pd.to_numeric(df[f'{side}_margin'], errors='coerce')\n",
    "            out['opp_margin']  = pd.to_numeric(df[f'{other}_margin'], errors='coerce')\n",
    "\n",
    "        if 'neutral_site' in df.columns:\n",
    "            out['neutral_site'] = pd.Series(df['neutral_site']).fillna(0).astype(int)\n",
    "\n",
    "        # copy per-game stats into standardized columns: <base> and opp_<base>\n",
    "        for b,(tc,oc) in base_map.items():\n",
    "            out[b] = pd.to_numeric(df[tc], errors='coerce')\n",
    "            out[f'opp_{b}'] = pd.to_numeric(df[oc], errors='coerce')\n",
    "\n",
    "        # standardized 1H / 2H points\n",
    "        if f'{side}_1h' in df.columns and f'{other}_1h' in df.columns:\n",
    "            out['points_1h']     = pd.to_numeric(df[f'{side}_1h'], errors='coerce')\n",
    "            out['opp_points_1h'] = pd.to_numeric(df[f'{other}_1h'], errors='coerce')\n",
    "\n",
    "        if f'{side}_2h' in df.columns and f'{other}_2h' in df.columns:\n",
    "            out['points_2h']     = pd.to_numeric(df[f'{side}_2h'], errors='coerce')\n",
    "            out['opp_points_2h'] = pd.to_numeric(df[f'{other}_2h'], errors='coerce')\n",
    "\n",
    "        return out\n",
    "\n",
    "    long_home = _make_team_rows('home')\n",
    "    long_away = _make_team_rows('away')\n",
    "    team_games = pd.concat([long_home, long_away], ignore_index=True)\n",
    "    team_games = team_games.sort_values(['team','season','game_dt','game_id']).reset_index(drop=True)\n",
    "\n",
    "    # --- 3) Rest days ---\n",
    "    # 3a) Historical per-game gaps for rolling features (UNCHANGED)\n",
    "    team_games['prev_game_dt'] = team_games.groupby(['team','season'])['game_dt'].shift(1)\n",
    "    team_games['rest_days_hist'] = (team_games['game_dt'] - team_games['prev_game_dt']).dt.days\n",
    "    team_games['rest_days_hist'] = team_games['rest_days_hist'].fillna(7)\n",
    "\n",
    "    # Rolling averages computed from historical gaps (UNCHANGED)\n",
    "    for w in windows:\n",
    "        team_games[f'ra_rest_days_w{w}'] = (\n",
    "            team_games.groupby(['team','season'])['rest_days_hist']\n",
    "            .transform(lambda s: s.rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "    # 3b) Current rest days for inference (CHANGED):\n",
    "    #     days since the last completed game to \"today_utc\"\n",
    "    last_game_dt = (\n",
    "        team_games.groupby(['team','season'], dropna=False)['game_dt']\n",
    "        .transform('max')\n",
    "    )\n",
    "    # compute per-row current rest (same within a team/season), but we'll only use it on the latest snapshot\n",
    "    team_games['rest_days_current'] = (today_utc - last_game_dt).dt.days.clip(lower=0)\n",
    "\n",
    "    # --- 4) Rolling/EWM features for team & allowed (NO shift for inference) ---\n",
    "    full_bases = [b for b in stat_bases if b in team_games.columns]\n",
    "\n",
    "    def _roll(s, w):  return s.rolling(w, min_periods=1).mean()\n",
    "    def _rstd(s, w):  return s.rolling(w, min_periods=2).std()\n",
    "    def _ewm(s, hl):  return s.ewm(halflife=hl, min_periods=1, adjust=False).mean()\n",
    "\n",
    "    for b in full_bases:\n",
    "        # team rolling\n",
    "        for w in windows:\n",
    "            team_games[f'ra_{b}_w{w}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _roll(s, w))\n",
    "        team_games[f'rstd_{b}_w5'] = team_games.groupby(['team','season'])[b].transform(lambda s: _rstd(s, 5))\n",
    "        team_games[f'ewm_{b}_hl{ewm_halflife}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _ewm(s, ewm_halflife))\n",
    "\n",
    "        # allowed\n",
    "        ob = f'opp_{b}'\n",
    "        if ob in team_games.columns:\n",
    "            for w in windows:\n",
    "                team_games[f'ra_allowed_{b}_w{w}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _roll(s, w))\n",
    "            team_games[f'rstd_allowed_{b}_w5'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _rstd(s, 5))\n",
    "            team_games[f'ewm_allowed_{b}_hl{ewm_halflife}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _ewm(s, ewm_halflife))\n",
    "\n",
    "    # 4b) 1H/2H rolling, allowed\n",
    "    for b in ['points_1h', 'points_2h']:\n",
    "        if b in team_games.columns:\n",
    "            for w in windows:\n",
    "                team_games[f'ra_{b}_w{w}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _roll(s, w))\n",
    "            ob = f'opp_{b}'\n",
    "            if ob in team_games.columns:\n",
    "                for w in windows:\n",
    "                    team_games[f'ra_allowed_{b}_w{w}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _roll(s, w))\n",
    "\n",
    "    # --- 5) Venue effects (home vs away) ---\n",
    "    if 'team_margin' in team_games.columns:\n",
    "        for w in windows:\n",
    "            team_games[f'ra_margin_homeonly_w{w}'] = (\n",
    "                team_games.groupby(['team','season','is_home'])['team_margin'].transform(lambda s: _roll(s, w))\n",
    "            )\n",
    "        for w in windows:\n",
    "            team_games[f'ra_margin_w{w}'] = team_games.groupby(['team','season'])['team_margin'].transform(lambda s: _roll(s, w))\n",
    "\n",
    "    # --- 6) Recent scoring form ---\n",
    "    if 'team_score' in team_games.columns and 'opp_score' in team_games.columns:\n",
    "        for w in windows:\n",
    "            pf = team_games.groupby(['team','season'])['team_score'].transform(lambda s: _roll(s, w))\n",
    "            pa = team_games.groupby(['team','season'])['opp_score' ].transform(lambda s: _roll(s, w))\n",
    "            team_games[f'ra_points_for_w{w}']     = pf\n",
    "            team_games[f'ra_points_against_w{w}'] = pa\n",
    "            team_games[f'ra_point_diff_w{w}']     = pf - pa\n",
    "\n",
    "    # --- 7) Build the \"pregame\" (inference) feature table ---\n",
    "    # We exclude raw current-game single-game columns that could leak (the current box score isn’t known)\n",
    "    leak_cols = ['points_1h','opp_points_1h','points_2h','opp_points_2h',\n",
    "                 'team_score','opp_score','team_margin','opp_margin','prev_game_dt']\n",
    "    raw_stat_cols = full_bases + [f'opp_{b}' for b in full_bases] + leak_cols\n",
    "    raw_stat_cols = [c for c in raw_stat_cols if c in team_games.columns]\n",
    "\n",
    "    feature_cols = [c for c in team_games.columns if c not in (raw_stat_cols + ['opponent'])]\n",
    "    pregame_team_features = team_games[feature_cols + ['opponent']].copy()\n",
    "\n",
    "    # --- 8) Latest snapshot per team-season (no leak; includes most recent game) ---\n",
    "    latest_snapshot = (\n",
    "        pregame_team_features\n",
    "        .sort_values(['team','season','game_dt','game_id'])\n",
    "        .groupby(['team','season'], as_index=False, sort=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Overwrite 'rest_days' in the latest snapshot with the \"today-based\" value\n",
    "    # (Keep rolling features ra_rest_days_w* as-is from historical gaps.)\n",
    "    if 'rest_days_current' in latest_snapshot.columns:\n",
    "        latest_snapshot['rest_days'] = latest_snapshot['rest_days_current']\n",
    "        latest_snapshot = latest_snapshot.drop(columns=['rest_days_current'])\n",
    "\n",
    "    # --- 9) Match your requested output column list (keep those that exist) ---\n",
    "    wanted = ['game_id', 'team', 'rest_days',\n",
    "              'ra_rest_days_w1','ra_rest_days_w3','ra_rest_days_w5','ra_rest_days_w10',\n",
    "              'ra_assists_w1','ra_allowed_assists_w1','ra_assists_w3','ra_allowed_assists_w3',\n",
    "              'ra_assists_w5','ra_allowed_assists_w5','ra_assists_w10','ra_allowed_assists_w10',\n",
    "              'rstd_assists_w5','ewm_assists_hl5','rstd_allowed_assists_w5','ewm_allowed_assists_hl5',\n",
    "              'ra_blocks_w1','ra_allowed_blocks_w1','ra_blocks_w3','ra_allowed_blocks_w3',\n",
    "              'ra_blocks_w5','ra_allowed_blocks_w5','ra_blocks_w10','ra_allowed_blocks_w10',\n",
    "              'rstd_blocks_w5','ewm_blocks_hl5','rstd_allowed_blocks_w5','ewm_allowed_blocks_hl5',\n",
    "              'ra_defensiveRebounds_w1','ra_allowed_defensiveRebounds_w1','ra_defensiveRebounds_w3',\n",
    "              'ra_allowed_defensiveRebounds_w3','ra_defensiveRebounds_w5','ra_allowed_defensiveRebounds_w5',\n",
    "              'ra_defensiveRebounds_w10','ra_allowed_defensiveRebounds_w10',\n",
    "              'rstd_defensiveRebounds_w5','ewm_defensiveRebounds_hl5',\n",
    "              'rstd_allowed_defensiveRebounds_w5','ewm_allowed_defensiveRebounds_hl5',\n",
    "              'ra_fastBreakPoints_w1','ra_allowed_fastBreakPoints_w1','ra_fastBreakPoints_w3',\n",
    "              'ra_allowed_fastBreakPoints_w3','ra_fastBreakPoints_w5','ra_allowed_fastBreakPoints_w5',\n",
    "              'ra_fastBreakPoints_w10','ra_allowed_fastBreakPoints_w10',\n",
    "              'rstd_fastBreakPoints_w5','ewm_fastBreakPoints_hl5',\n",
    "              'rstd_allowed_fastBreakPoints_w5','ewm_allowed_fastBreakPoints_hl5',\n",
    "              'ra_flagrantFouls_w1','ra_allowed_flagrantFouls_w1','ra_flagrantFouls_w3',\n",
    "              'ra_allowed_flagrantFouls_w3','ra_flagrantFouls_w5','ra_allowed_flagrantFouls_w5',\n",
    "              'ra_flagrantFouls_w10','ra_allowed_flagrantFouls_w10',\n",
    "              'rstd_flagrantFouls_w5','ewm_flagrantFouls_hl5',\n",
    "              'rstd_allowed_flagrantFouls_w5','ewm_allowed_flagrantFouls_hl5',\n",
    "              'ra_fouls_w1','ra_allowed_fouls_w1','ra_fouls_w3','ra_allowed_fouls_w3',\n",
    "              'ra_fouls_w5','ra_allowed_fouls_w5','ra_fouls_w10','ra_allowed_fouls_w10',\n",
    "              'rstd_fouls_w5','ewm_fouls_hl5','rstd_allowed_fouls_w5','ewm_allowed_fouls_hl5',\n",
    "              'ra_offensiveRebounds_w1','ra_allowed_offensiveRebounds_w1','ra_offensiveRebounds_w3',\n",
    "              'ra_allowed_offensiveRebounds_w3','ra_offensiveRebounds_w5','ra_allowed_offensiveRebounds_w5',\n",
    "              'ra_offensiveRebounds_w10','ra_allowed_offensiveRebounds_w10',\n",
    "              'rstd_offensiveRebounds_w5','ewm_offensiveRebounds_hl5',\n",
    "              'rstd_allowed_offensiveRebounds_w5','ewm_allowed_offensiveRebounds_hl5',\n",
    "              'ra_pointsInPaint_w1','ra_allowed_pointsInPaint_w1','ra_pointsInPaint_w3',\n",
    "              'ra_allowed_pointsInPaint_w3','ra_pointsInPaint_w5','ra_allowed_pointsInPaint_w5',\n",
    "              'ra_pointsInPaint_w10','ra_allowed_pointsInPaint_w10',\n",
    "              'rstd_pointsInPaint_w5','ewm_pointsInPaint_hl5',\n",
    "              'rstd_allowed_pointsInPaint_w5','ewm_allowed_pointsInPaint_hl5',\n",
    "              'ra_steals_w1','ra_allowed_steals_w1','ra_steals_w3','ra_allowed_steals_w3',\n",
    "              'ra_steals_w5','ra_allowed_steals_w5','ra_steals_w10','ra_allowed_steals_w10',\n",
    "              'rstd_steals_w5','ewm_steals_hl5','rstd_allowed_steals_w5','ewm_allowed_steals_hl5',\n",
    "              'ra_technicalFouls_w1','ra_allowed_technicalFouls_w1','ra_technicalFouls_w3',\n",
    "              'ra_allowed_technicalFouls_w3','ra_technicalFouls_w5','ra_allowed_technicalFouls_w5',\n",
    "              'ra_technicalFouls_w10','ra_allowed_technicalFouls_w10',\n",
    "              'rstd_technicalFouls_w5','ewm_technicalFouls_hl5',\n",
    "              'rstd_allowed_technicalFouls_w5','ewm_allowed_technicalFouls_hl5',\n",
    "              'ra_totalRebounds_w1','ra_allowed_totalRebounds_w1','ra_totalRebounds_w3',\n",
    "              'ra_allowed_totalRebounds_w3','ra_totalRebounds_w5','ra_allowed_totalRebounds_w5',\n",
    "              'ra_totalRebounds_w10','ra_allowed_totalRebounds_w10',\n",
    "              'rstd_totalRebounds_w5','ewm_totalRebounds_hl5',\n",
    "              'rstd_allowed_totalRebounds_w5','ewm_allowed_totalRebounds_hl5',\n",
    "              'ra_turnoverPoints_w1','ra_allowed_turnoverPoints_w1','ra_turnoverPoints_w3',\n",
    "              'ra_allowed_turnoverPoints_w3','ra_turnoverPoints_w5','ra_allowed_turnoverPoints_w5',\n",
    "              'ra_turnoverPoints_w10','ra_allowed_turnoverPoints_w10',\n",
    "              'rstd_turnoverPoints_w5','ewm_turnoverPoints_hl5',\n",
    "              'rstd_allowed_turnoverPoints_w5','ewm_allowed_turnoverPoints_hl5',\n",
    "              'ra_turnovers_w1','ra_allowed_turnovers_w1','ra_turnovers_w3','ra_allowed_turnovers_w3',\n",
    "              'ra_turnovers_w5','ra_allowed_turnovers_w5','ra_turnovers_w10','ra_allowed_turnovers_w10',\n",
    "              'rstd_turnovers_w5','ewm_turnovers_hl5','rstd_allowed_turnovers_w5','ewm_allowed_turnovers_hl5',\n",
    "              'ra_points_1h_w1','ra_points_1h_w3','ra_points_1h_w5','ra_points_1h_w10',\n",
    "              'ra_allowed_points_1h_w1','ra_allowed_points_1h_w3','ra_allowed_points_1h_w5','ra_allowed_points_1h_w10',\n",
    "              'ra_points_2h_w1','ra_points_2h_w3','ra_points_2h_w5','ra_points_2h_w10',\n",
    "              'ra_allowed_points_2h_w1','ra_allowed_points_2h_w3','ra_allowed_points_2h_w5','ra_allowed_points_2h_w10',\n",
    "              'ra_margin_homeonly_w1','ra_margin_homeonly_w3','ra_margin_homeonly_w5','ra_margin_homeonly_w10',\n",
    "              'ra_points_for_w1','ra_points_against_w1','ra_point_diff_w1',\n",
    "              'ra_points_for_w3','ra_points_against_w3','ra_point_diff_w3',\n",
    "              'ra_points_for_w5','ra_points_against_w5','ra_point_diff_w5',\n",
    "              'ra_points_for_w10','ra_points_against_w10','ra_point_diff_w10',\n",
    "              'ra_margin_w1','ra_margin_w3','ra_margin_w5','ra_margin_w10'\n",
    "             ]\n",
    "\n",
    "    keep = [c for c in wanted if c in latest_snapshot.columns]\n",
    "    features_3 = latest_snapshot[['team'] + keep] if 'team' not in keep else latest_snapshot[keep]\n",
    "\n",
    "    return features_3\n",
    "\n",
    "# -----------------------\n",
    "# USAGE\n",
    "# -----------------------\n",
    "features_3 = build_cbb_features_inference(\n",
    "    merged_df[['game_id','season','date','date_utc','time_utc','neutral_site','home','away',\n",
    "               'home_1h','away_1h','home_2h','away_2h','home_score','away_score',\n",
    "               'home_margin','away_margin',\n",
    "               'assists_home','fouls_home','technicalFouls_home','flagrantFouls_home',\n",
    "               'totalRebounds_home','offensiveRebounds_home','defensiveRebounds_home',\n",
    "               'pointsInPaint_home','turnovers_home','turnoverPoints_home','steals_home',\n",
    "               'blocks_home','fastBreakPoints_home',\n",
    "               'assists_away','fouls_away','technicalFouls_away','flagrantFouls_away',\n",
    "               'totalRebounds_away','offensiveRebounds_away','defensiveRebounds_away',\n",
    "               'pointsInPaint_away','turnovers_away','turnoverPoints_away','steals_away',\n",
    "               'blocks_away','fastBreakPoints_away']]\n",
    ")\n",
    "\n",
    "# features_3: one row per team-season, with the rolling/EWM features\n",
    "assert len(set(list(features_3.columns)) - set(['game_id', 'team', 'rest_days', 'ra_rest_days_w1', 'ra_rest_days_w3', 'ra_rest_days_w5', 'ra_rest_days_w10', 'ra_assists_w1', 'ra_allowed_assists_w1', 'ra_assists_w3', 'ra_allowed_assists_w3', 'ra_assists_w5', 'ra_allowed_assists_w5', 'ra_assists_w10', 'ra_allowed_assists_w10', 'rstd_assists_w5', 'ewm_assists_hl5', 'rstd_allowed_assists_w5', 'ewm_allowed_assists_hl5', 'ra_blocks_w1', 'ra_allowed_blocks_w1', 'ra_blocks_w3', 'ra_allowed_blocks_w3', 'ra_blocks_w5', 'ra_allowed_blocks_w5', 'ra_blocks_w10', 'ra_allowed_blocks_w10', 'rstd_blocks_w5', 'ewm_blocks_hl5', 'rstd_allowed_blocks_w5', 'ewm_allowed_blocks_hl5', 'ra_defensiveRebounds_w1', 'ra_allowed_defensiveRebounds_w1', 'ra_defensiveRebounds_w3', 'ra_allowed_defensiveRebounds_w3', 'ra_defensiveRebounds_w5', 'ra_allowed_defensiveRebounds_w5', 'ra_defensiveRebounds_w10', 'ra_allowed_defensiveRebounds_w10', 'rstd_defensiveRebounds_w5', 'ewm_defensiveRebounds_hl5', 'rstd_allowed_defensiveRebounds_w5', 'ewm_allowed_defensiveRebounds_hl5', 'ra_fastBreakPoints_w1', 'ra_allowed_fastBreakPoints_w1', 'ra_fastBreakPoints_w3', 'ra_allowed_fastBreakPoints_w3', 'ra_fastBreakPoints_w5', 'ra_allowed_fastBreakPoints_w5', 'ra_fastBreakPoints_w10', 'ra_allowed_fastBreakPoints_w10', 'rstd_fastBreakPoints_w5', 'ewm_fastBreakPoints_hl5', 'rstd_allowed_fastBreakPoints_w5', 'ewm_allowed_fastBreakPoints_hl5', 'ra_flagrantFouls_w1', 'ra_allowed_flagrantFouls_w1', 'ra_flagrantFouls_w3', 'ra_allowed_flagrantFouls_w3', 'ra_flagrantFouls_w5', 'ra_allowed_flagrantFouls_w5', 'ra_flagrantFouls_w10', 'ra_allowed_flagrantFouls_w10', 'rstd_flagrantFouls_w5', 'ewm_flagrantFouls_hl5', 'rstd_allowed_flagrantFouls_w5', 'ewm_allowed_flagrantFouls_hl5', 'ra_fouls_w1', 'ra_allowed_fouls_w1', 'ra_fouls_w3', 'ra_allowed_fouls_w3', 'ra_fouls_w5', 'ra_allowed_fouls_w5', 'ra_fouls_w10', 'ra_allowed_fouls_w10', 'rstd_fouls_w5', 'ewm_fouls_hl5', 'rstd_allowed_fouls_w5', 'ewm_allowed_fouls_hl5', 'ra_offensiveRebounds_w1', 'ra_allowed_offensiveRebounds_w1', 'ra_offensiveRebounds_w3', 'ra_allowed_offensiveRebounds_w3', 'ra_offensiveRebounds_w5', 'ra_allowed_offensiveRebounds_w5', 'ra_offensiveRebounds_w10', 'ra_allowed_offensiveRebounds_w10', 'rstd_offensiveRebounds_w5', 'ewm_offensiveRebounds_hl5', 'rstd_allowed_offensiveRebounds_w5', 'ewm_allowed_offensiveRebounds_hl5', 'ra_pointsInPaint_w1', 'ra_allowed_pointsInPaint_w1', 'ra_pointsInPaint_w3', 'ra_allowed_pointsInPaint_w3', 'ra_pointsInPaint_w5', 'ra_allowed_pointsInPaint_w5', 'ra_pointsInPaint_w10', 'ra_allowed_pointsInPaint_w10', 'rstd_pointsInPaint_w5', 'ewm_pointsInPaint_hl5', 'rstd_allowed_pointsInPaint_w5', 'ewm_allowed_pointsInPaint_hl5', 'ra_steals_w1', 'ra_allowed_steals_w1', 'ra_steals_w3', 'ra_allowed_steals_w3', 'ra_steals_w5', 'ra_allowed_steals_w5', 'ra_steals_w10', 'ra_allowed_steals_w10', 'rstd_steals_w5', 'ewm_steals_hl5', 'rstd_allowed_steals_w5', 'ewm_allowed_steals_hl5', 'ra_technicalFouls_w1', 'ra_allowed_technicalFouls_w1', 'ra_technicalFouls_w3', 'ra_allowed_technicalFouls_w3', 'ra_technicalFouls_w5', 'ra_allowed_technicalFouls_w5', 'ra_technicalFouls_w10', 'ra_allowed_technicalFouls_w10', 'rstd_technicalFouls_w5', 'ewm_technicalFouls_hl5', 'rstd_allowed_technicalFouls_w5', 'ewm_allowed_technicalFouls_hl5', 'ra_totalRebounds_w1', 'ra_allowed_totalRebounds_w1', 'ra_totalRebounds_w3', 'ra_allowed_totalRebounds_w3', 'ra_totalRebounds_w5', 'ra_allowed_totalRebounds_w5', 'ra_totalRebounds_w10', 'ra_allowed_totalRebounds_w10', 'rstd_totalRebounds_w5', 'ewm_totalRebounds_hl5', 'rstd_allowed_totalRebounds_w5', 'ewm_allowed_totalRebounds_hl5', 'ra_turnoverPoints_w1', 'ra_allowed_turnoverPoints_w1', 'ra_turnoverPoints_w3', 'ra_allowed_turnoverPoints_w3', 'ra_turnoverPoints_w5', 'ra_allowed_turnoverPoints_w5', 'ra_turnoverPoints_w10', 'ra_allowed_turnoverPoints_w10', 'rstd_turnoverPoints_w5', 'ewm_turnoverPoints_hl5', 'rstd_allowed_turnoverPoints_w5', 'ewm_allowed_turnoverPoints_hl5', 'ra_turnovers_w1', 'ra_allowed_turnovers_w1', 'ra_turnovers_w3', 'ra_allowed_turnovers_w3', 'ra_turnovers_w5', 'ra_allowed_turnovers_w5', 'ra_turnovers_w10', 'ra_allowed_turnovers_w10', 'rstd_turnovers_w5', 'ewm_turnovers_hl5', 'rstd_allowed_turnovers_w5', 'ewm_allowed_turnovers_hl5', 'ra_points_1h_w1', 'ra_points_1h_w3', 'ra_points_1h_w5', 'ra_points_1h_w10', 'ra_allowed_points_1h_w1', 'ra_allowed_points_1h_w3', 'ra_allowed_points_1h_w5', 'ra_allowed_points_1h_w10', 'ra_points_2h_w1', 'ra_points_2h_w3', 'ra_points_2h_w5', 'ra_points_2h_w10', 'ra_allowed_points_2h_w1', 'ra_allowed_points_2h_w3', 'ra_allowed_points_2h_w5', 'ra_allowed_points_2h_w10', 'ra_margin_homeonly_w1', 'ra_margin_homeonly_w3', 'ra_margin_homeonly_w5', 'ra_margin_homeonly_w10', 'ra_points_for_w1', 'ra_points_against_w1', 'ra_point_diff_w1', 'ra_points_for_w3', 'ra_points_against_w3', 'ra_point_diff_w3', 'ra_points_for_w5', 'ra_points_against_w5', 'ra_point_diff_w5', 'ra_points_for_w10', 'ra_points_against_w10', 'ra_point_diff_w10', 'ra_margin_w1', 'ra_margin_w3', 'ra_margin_w5', 'ra_margin_w10'])) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "game_info = pd.read_csv(\"daily-games/daily.csv\", index_col=0)\n",
    "game_info['game_id']  = game_info['game_id'].astype(str)\n",
    "features_1['game_id'] = features_1['game_id'].astype(str)\n",
    "features_2['game_id'] = features_2['game_id'].astype(str)\n",
    "features_3['game_id'] = features_3['game_id'].astype(str)\n",
    "game_info = game_info.merge(features_1, on=\"game_id\", how=\"left\")\n",
    "\n",
    "home_merge = features_2.copy()\n",
    "home_merge = home_merge.rename(columns=lambda c: f\"{c}_home\" if c not in [\"game_id\", \"team\", \"opponent\"] else c)\n",
    "merged_home = game_info.merge(\n",
    "    home_merge,\n",
    "    left_on=\"home\",\n",
    "    right_on=\"team\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"team\", \"opponent\"])\n",
    "\n",
    "# --- AWAY TEAM MERGE ---\n",
    "away_merge = features_2.copy()\n",
    "away_merge = away_merge.rename(columns=lambda c: f\"{c}_away\" if c not in [\"game_id\", \"team\", \"opponent\"] else c)\n",
    "game_info = merged_home.merge(\n",
    "    away_merge,\n",
    "    left_on=\"away\",\n",
    "    right_on=\"team\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"team\", \"opponent\"])\n",
    "\n",
    "key_cols = ['game_id', 'team']\n",
    "\n",
    "# --- HOME merge ---\n",
    "home_feats = features_3.copy()\n",
    "home_feats = home_feats.rename(columns=lambda c: f\"{c}_home\" if c not in key_cols else c)\n",
    "\n",
    "out = game_info.merge(\n",
    "    home_feats,\n",
    "    left_on='home',\n",
    "    right_on='team',\n",
    "    how='left',\n",
    ").drop(columns=['team'])\n",
    "\n",
    "# --- AWAY merge ---\n",
    "away_feats = features_3.copy()\n",
    "away_feats = away_feats.rename(columns=lambda c: f\"{c}_away\" if c not in key_cols else c)\n",
    "\n",
    "game_info = out.merge(\n",
    "    away_feats,\n",
    "    left_on='away',\n",
    "    right_on='team',\n",
    "    how='left',\n",
    ").drop(columns=['team'])\n",
    "\n",
    "game_info = game_info.dropna(subset=[\"home\", \"away\"])\n",
    "os.makedirs(f\"data/inference/{DATE}/\", exist_ok=True)\n",
    "game_info[~((game_info['ra_allowed_defensiveRebounds_w1_home'].isna()) & (game_info['ra_allowed_defensiveRebounds_w1_home'].isna()))].to_csv(f\"data/inference/{DATE}/inference_data.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id_x</th>\n",
       "      <th>date</th>\n",
       "      <th>date_key</th>\n",
       "      <th>date_utc</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>neutral_site</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>conf_home</th>\n",
       "      <th>conf_away</th>\n",
       "      <th>...</th>\n",
       "      <th>ra_points_for_w5_away</th>\n",
       "      <th>ra_points_against_w5_away</th>\n",
       "      <th>ra_point_diff_w5_away</th>\n",
       "      <th>ra_points_for_w10_away</th>\n",
       "      <th>ra_points_against_w10_away</th>\n",
       "      <th>ra_point_diff_w10_away</th>\n",
       "      <th>ra_margin_w1_away</th>\n",
       "      <th>ra_margin_w3_away</th>\n",
       "      <th>ra_margin_w5_away</th>\n",
       "      <th>ra_margin_w10_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401809074</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mount St. Mary</td>\n",
       "      <td>Bucknell</td>\n",
       "      <td>MAAC</td>\n",
       "      <td>Pat</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401813757</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>03:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>P12</td>\n",
       "      <td>WCC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401808949</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Southeastern Louisiana</td>\n",
       "      <td>SB</td>\n",
       "      <td>Slnd</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401822724</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>23:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>B10</td>\n",
       "      <td>BE</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401824945</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>DePaul</td>\n",
       "      <td>Stonehill</td>\n",
       "      <td>BE</td>\n",
       "      <td>NEC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401822366</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Eastern Illinois</td>\n",
       "      <td>Nicholls St.</td>\n",
       "      <td>OVC</td>\n",
       "      <td>Slnd</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401817164</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>23:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>A10</td>\n",
       "      <td>Amer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>401824357</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>23:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Northwestern</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>B10</td>\n",
       "      <td>Pat</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>401818298</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Navy</td>\n",
       "      <td>Yale</td>\n",
       "      <td>Pat</td>\n",
       "      <td>Ivy</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>401823426</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>23:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Horz</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>401826869</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>B10</td>\n",
       "      <td>Horz</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>401823647</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Western Illinois</td>\n",
       "      <td>B10</td>\n",
       "      <td>OVC</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>401823392</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>23:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Ohio St.</td>\n",
       "      <td>Purdue Fort Wayne</td>\n",
       "      <td>B10</td>\n",
       "      <td>Horz</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>401824868</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Furman</td>\n",
       "      <td>Troy</td>\n",
       "      <td>SC</td>\n",
       "      <td>SB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>401817442</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Longwood</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BSth</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>401813445</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Duquesne</td>\n",
       "      <td>Sacred Heart</td>\n",
       "      <td>A10</td>\n",
       "      <td>NEC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>401823461</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Northern Illinois</td>\n",
       "      <td>B10</td>\n",
       "      <td>MAC</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>401823225</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Florida Gulf Coast</td>\n",
       "      <td>B10</td>\n",
       "      <td>ASun</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>401826804</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>03:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rice</td>\n",
       "      <td>P12</td>\n",
       "      <td>Amer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>401819899</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>Sam Houston St.</td>\n",
       "      <td>B12</td>\n",
       "      <td>CUSA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>401828492</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Louisiana Monroe</td>\n",
       "      <td>SEC</td>\n",
       "      <td>SB</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>401812917</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>Gardner Webb</td>\n",
       "      <td>ACC</td>\n",
       "      <td>BSth</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>401824055</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>03:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Oregon St.</td>\n",
       "      <td>Illinois Chicago</td>\n",
       "      <td>P12</td>\n",
       "      <td>MVC</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>401819843</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Georgia St.</td>\n",
       "      <td>B12</td>\n",
       "      <td>SB</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>401817528</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>Morehead St.</td>\n",
       "      <td>ACC</td>\n",
       "      <td>OVC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>401826860</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Murray St.</td>\n",
       "      <td>Mississippi Valley St.</td>\n",
       "      <td>MVC</td>\n",
       "      <td>SWAC</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>401829430</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>03:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Saint Mary</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>SC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>401817263</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>ACC</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>401826706</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Florida St.</td>\n",
       "      <td>Alabama St.</td>\n",
       "      <td>ACC</td>\n",
       "      <td>SWAC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>401822330</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Valparaiso</td>\n",
       "      <td>SEC</td>\n",
       "      <td>MVC</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>401817132</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>Detroit Mercy</td>\n",
       "      <td>ACC</td>\n",
       "      <td>Horz</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>401824023</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>02:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Utah Tech</td>\n",
       "      <td>P12</td>\n",
       "      <td>WAC</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>401826698</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>George Mason</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>A10</td>\n",
       "      <td>BSth</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>401829277</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Samford</td>\n",
       "      <td>South Carolina St.</td>\n",
       "      <td>SC</td>\n",
       "      <td>MEAC</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>401826892</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Seton Hall</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>BE</td>\n",
       "      <td>NEC</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>401820614</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>ACC</td>\n",
       "      <td>AE</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>401823514</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>01:30Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Southern Indiana</td>\n",
       "      <td>VMI</td>\n",
       "      <td>OVC</td>\n",
       "      <td>SC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>401817253</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>02:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>N.C. State</td>\n",
       "      <td>UAB</td>\n",
       "      <td>ACC</td>\n",
       "      <td>Amer</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>401827273</td>\n",
       "      <td>20251107</td>\n",
       "      <td>20251107</td>\n",
       "      <td>2025-11-07</td>\n",
       "      <td>22:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Colgate</td>\n",
       "      <td>Northeastern</td>\n",
       "      <td>Pat</td>\n",
       "      <td>CAA</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>401823002</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>02:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Grand Canyon</td>\n",
       "      <td>Youngstown St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>Horz</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>401820797</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Tennessee Tech</td>\n",
       "      <td>Amer</td>\n",
       "      <td>OVC</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>401817487</td>\n",
       "      <td>20251108</td>\n",
       "      <td>20251108</td>\n",
       "      <td>2025-11-08</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>North Carolina Central</td>\n",
       "      <td>ACC</td>\n",
       "      <td>MEAC</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>-48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id_x      date  date_key    date_utc time_utc  neutral_site  \\\n",
       "0   401809074  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "1   401813757  20251108  20251108  2025-11-08   03:30Z             0   \n",
       "2   401808949  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "3   401822724  20251107  20251107  2025-11-07   23:00Z             0   \n",
       "6   401824945  20251108  20251108  2025-11-08   01:00Z             0   \n",
       "8   401822366  20251108  20251108  2025-11-08   01:00Z             0   \n",
       "9   401817164  20251107  20251107  2025-11-07   23:00Z             1   \n",
       "10  401824357  20251107  20251107  2025-11-07   23:00Z             0   \n",
       "11  401818298  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "12  401823426  20251107  20251107  2025-11-07   23:30Z             0   \n",
       "14  401826869  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "15  401823647  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "16  401823392  20251107  20251107  2025-11-07   23:30Z             0   \n",
       "17  401824868  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "20  401817442  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "21  401813445  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "26  401823461  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "28  401823225  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "29  401826804  20251108  20251108  2025-11-08   03:00Z             0   \n",
       "32  401819899  20251108  20251108  2025-11-08   01:00Z             0   \n",
       "33  401828492  20251108  20251108  2025-11-08   00:30Z             0   \n",
       "34  401812917  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "35  401824055  20251108  20251108  2025-11-08   03:00Z             0   \n",
       "37  401819843  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "39  401817528  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "41  401826860  20251108  20251108  2025-11-08   01:00Z             0   \n",
       "42  401829430  20251108  20251108  2025-11-08   03:30Z             0   \n",
       "44  401817263  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "46  401826706  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "51  401822330  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "52  401817132  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "53  401824023  20251108  20251108  2025-11-08   02:00Z             0   \n",
       "57  401826698  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "58  401829277  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "59  401826892  20251108  20251108  2025-11-08   00:30Z             0   \n",
       "60  401820614  20251108  20251108  2025-11-08   00:30Z             0   \n",
       "61  401823514  20251108  20251108  2025-11-08   01:30Z             0   \n",
       "62  401817253  20251108  20251108  2025-11-08   02:00Z             0   \n",
       "67  401827273  20251107  20251107  2025-11-07   22:00Z             0   \n",
       "68  401823002  20251108  20251108  2025-11-08   02:00Z             0   \n",
       "72  401820797  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "73  401817487  20251108  20251108  2025-11-08   00:00Z             0   \n",
       "\n",
       "                home                    away conf_home conf_away  ...  \\\n",
       "0     Mount St. Mary                Bucknell      MAAC       Pat  ...   \n",
       "1               UCLA              Pepperdine       P12       WCC  ...   \n",
       "2          Louisiana  Southeastern Louisiana        SB      Slnd  ...   \n",
       "3           Maryland              Georgetown       B10        BE  ...   \n",
       "6             DePaul               Stonehill        BE       NEC  ...   \n",
       "8   Eastern Illinois            Nicholls St.       OVC      Slnd  ...   \n",
       "9       Rhode Island                   Tulsa       A10      Amer  ...   \n",
       "10      Northwestern       Boston University       B10       Pat  ...   \n",
       "11              Navy                    Yale       Pat       Ivy  ...   \n",
       "12           Buffalo               Green Bay       MAC      Horz  ...   \n",
       "14            Purdue                 Oakland       B10      Horz  ...   \n",
       "15              Iowa        Western Illinois       B10       OVC  ...   \n",
       "16          Ohio St.       Purdue Fort Wayne       B10      Horz  ...   \n",
       "17            Furman                    Troy        SC        SB  ...   \n",
       "20        Pittsburgh                Longwood       ACC      BSth  ...   \n",
       "21          Duquesne            Sacred Heart       A10       NEC  ...   \n",
       "26         Wisconsin       Northern Illinois       B10       MAC  ...   \n",
       "28          Illinois      Florida Gulf Coast       B10      ASun  ...   \n",
       "29            Oregon                    Rice       P12      Amer  ...   \n",
       "32        Texas Tech         Sam Houston St.       B12      CUSA  ...   \n",
       "33       Mississippi        Louisiana Monroe       SEC        SB  ...   \n",
       "34           Clemson            Gardner Webb       ACC      BSth  ...   \n",
       "35        Oregon St.        Illinois Chicago       P12       MVC  ...   \n",
       "37        Cincinnati             Georgia St.       B12        SB  ...   \n",
       "39       Wake Forest            Morehead St.       ACC       OVC  ...   \n",
       "41        Murray St.  Mississippi Valley St.       MVC      SWAC  ...   \n",
       "42        Saint Mary             Chattanooga       WCC        SC  ...   \n",
       "44    North Carolina                  Kansas       ACC       B12  ...   \n",
       "46       Florida St.             Alabama St.       ACC      SWAC  ...   \n",
       "51          Kentucky              Valparaiso       SEC       MVC  ...   \n",
       "52        Notre Dame           Detroit Mercy       ACC      Horz  ...   \n",
       "53           Arizona               Utah Tech       P12       WAC  ...   \n",
       "57      George Mason                Winthrop       A10      BSth  ...   \n",
       "58           Samford      South Carolina St.        SC      MEAC  ...   \n",
       "59        Seton Hall                  Wagner        BE       NEC  ...   \n",
       "60      Georgia Tech                  Bryant       ACC        AE  ...   \n",
       "61  Southern Indiana                     VMI       OVC        SC  ...   \n",
       "62        N.C. State                     UAB       ACC      Amer  ...   \n",
       "67           Colgate            Northeastern       Pat       CAA  ...   \n",
       "68      Grand Canyon          Youngstown St.       WAC      Horz  ...   \n",
       "72         Charlotte          Tennessee Tech      Amer       OVC  ...   \n",
       "73          Virginia  North Carolina Central       ACC      MEAC  ...   \n",
       "\n",
       "    ra_points_for_w5_away  ra_points_against_w5_away  ra_point_diff_w5_away  \\\n",
       "0                    78.0                       70.0                    8.0   \n",
       "1                     NaN                        NaN                    NaN   \n",
       "2                    58.0                       88.0                  -30.0   \n",
       "3                    87.0                       70.0                   17.0   \n",
       "6                     NaN                        NaN                    NaN   \n",
       "8                    51.0                       77.0                  -26.0   \n",
       "9                     NaN                        NaN                    NaN   \n",
       "10                   76.0                       75.0                    1.0   \n",
       "11                    NaN                        NaN                    NaN   \n",
       "12                   51.0                       94.0                  -43.0   \n",
       "14                   78.0                      121.0                  -43.0   \n",
       "15                   75.0                       80.0                   -5.0   \n",
       "16                   71.0                       90.0                  -19.0   \n",
       "17                    NaN                        NaN                    NaN   \n",
       "20                    NaN                        NaN                    NaN   \n",
       "21                    NaN                        NaN                    NaN   \n",
       "26                  102.0                       82.0                   20.0   \n",
       "28                    NaN                        NaN                    NaN   \n",
       "29                    NaN                        NaN                    NaN   \n",
       "32                    NaN                        NaN                    NaN   \n",
       "33                   82.0                      102.0                  -20.0   \n",
       "34                   60.0                       87.0                  -27.0   \n",
       "35                   91.0                       71.0                   20.0   \n",
       "37                   49.0                       71.0                  -22.0   \n",
       "39                    NaN                        NaN                    NaN   \n",
       "41                   55.0                      106.0                  -51.0   \n",
       "42                    NaN                        NaN                    NaN   \n",
       "44                   94.0                       51.0                   43.0   \n",
       "46                    NaN                        NaN                    NaN   \n",
       "51                   66.0                       63.0                    3.0   \n",
       "52                   71.0                       91.0                  -20.0   \n",
       "53                   81.0                       79.0                    2.0   \n",
       "57                   81.0                       74.0                    7.0   \n",
       "58                   45.0                      104.0                  -59.0   \n",
       "59                   74.0                      103.0                  -29.0   \n",
       "60                   66.0                       82.0                  -16.0   \n",
       "61                    NaN                        NaN                    NaN   \n",
       "62                  106.0                       55.0                   51.0   \n",
       "67                   75.0                       76.0                   -1.0   \n",
       "68                   59.0                       74.0                  -15.0   \n",
       "72                   70.0                       82.0                  -12.0   \n",
       "73                   66.0                      114.0                  -48.0   \n",
       "\n",
       "    ra_points_for_w10_away  ra_points_against_w10_away  \\\n",
       "0                     78.0                        70.0   \n",
       "1                      NaN                         NaN   \n",
       "2                     58.0                        88.0   \n",
       "3                     87.0                        70.0   \n",
       "6                      NaN                         NaN   \n",
       "8                     51.0                        77.0   \n",
       "9                      NaN                         NaN   \n",
       "10                    76.0                        75.0   \n",
       "11                     NaN                         NaN   \n",
       "12                    51.0                        94.0   \n",
       "14                    78.0                       121.0   \n",
       "15                    75.0                        80.0   \n",
       "16                    71.0                        90.0   \n",
       "17                     NaN                         NaN   \n",
       "20                     NaN                         NaN   \n",
       "21                     NaN                         NaN   \n",
       "26                   102.0                        82.0   \n",
       "28                     NaN                         NaN   \n",
       "29                     NaN                         NaN   \n",
       "32                     NaN                         NaN   \n",
       "33                    82.0                       102.0   \n",
       "34                    60.0                        87.0   \n",
       "35                    91.0                        71.0   \n",
       "37                    49.0                        71.0   \n",
       "39                     NaN                         NaN   \n",
       "41                    55.0                       106.0   \n",
       "42                     NaN                         NaN   \n",
       "44                    94.0                        51.0   \n",
       "46                     NaN                         NaN   \n",
       "51                    66.0                        63.0   \n",
       "52                    71.0                        91.0   \n",
       "53                    81.0                        79.0   \n",
       "57                    81.0                        74.0   \n",
       "58                    45.0                       104.0   \n",
       "59                    74.0                       103.0   \n",
       "60                    66.0                        82.0   \n",
       "61                     NaN                         NaN   \n",
       "62                   106.0                        55.0   \n",
       "67                    75.0                        76.0   \n",
       "68                    59.0                        74.0   \n",
       "72                    70.0                        82.0   \n",
       "73                    66.0                       114.0   \n",
       "\n",
       "    ra_point_diff_w10_away  ra_margin_w1_away  ra_margin_w3_away  \\\n",
       "0                      8.0                8.0                8.0   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                    -30.0              -30.0              -30.0   \n",
       "3                     17.0               17.0               17.0   \n",
       "6                      NaN                NaN                NaN   \n",
       "8                    -26.0              -26.0              -26.0   \n",
       "9                      NaN                NaN                NaN   \n",
       "10                     1.0                1.0                1.0   \n",
       "11                     NaN                NaN                NaN   \n",
       "12                   -43.0              -43.0              -43.0   \n",
       "14                   -43.0              -43.0              -43.0   \n",
       "15                    -5.0               -5.0               -5.0   \n",
       "16                   -19.0              -19.0              -19.0   \n",
       "17                     NaN                NaN                NaN   \n",
       "20                     NaN                NaN                NaN   \n",
       "21                     NaN                NaN                NaN   \n",
       "26                    20.0               20.0               20.0   \n",
       "28                     NaN                NaN                NaN   \n",
       "29                     NaN                NaN                NaN   \n",
       "32                     NaN                NaN                NaN   \n",
       "33                   -20.0              -20.0              -20.0   \n",
       "34                   -27.0              -27.0              -27.0   \n",
       "35                    20.0               20.0               20.0   \n",
       "37                   -22.0              -22.0              -22.0   \n",
       "39                     NaN                NaN                NaN   \n",
       "41                   -51.0              -51.0              -51.0   \n",
       "42                     NaN                NaN                NaN   \n",
       "44                    43.0               43.0               43.0   \n",
       "46                     NaN                NaN                NaN   \n",
       "51                     3.0                3.0                3.0   \n",
       "52                   -20.0              -20.0              -20.0   \n",
       "53                     2.0                2.0                2.0   \n",
       "57                     7.0                7.0                7.0   \n",
       "58                   -59.0              -59.0              -59.0   \n",
       "59                   -29.0              -29.0              -29.0   \n",
       "60                   -16.0              -16.0              -16.0   \n",
       "61                     NaN                NaN                NaN   \n",
       "62                    51.0               51.0               51.0   \n",
       "67                    -1.0               -1.0               -1.0   \n",
       "68                   -15.0              -15.0              -15.0   \n",
       "72                   -12.0              -12.0              -12.0   \n",
       "73                   -48.0              -48.0              -48.0   \n",
       "\n",
       "    ra_margin_w5_away  ra_margin_w10_away  \n",
       "0                 8.0                 8.0  \n",
       "1                 NaN                 NaN  \n",
       "2               -30.0               -30.0  \n",
       "3                17.0                17.0  \n",
       "6                 NaN                 NaN  \n",
       "8               -26.0               -26.0  \n",
       "9                 NaN                 NaN  \n",
       "10                1.0                 1.0  \n",
       "11                NaN                 NaN  \n",
       "12              -43.0               -43.0  \n",
       "14              -43.0               -43.0  \n",
       "15               -5.0                -5.0  \n",
       "16              -19.0               -19.0  \n",
       "17                NaN                 NaN  \n",
       "20                NaN                 NaN  \n",
       "21                NaN                 NaN  \n",
       "26               20.0                20.0  \n",
       "28                NaN                 NaN  \n",
       "29                NaN                 NaN  \n",
       "32                NaN                 NaN  \n",
       "33              -20.0               -20.0  \n",
       "34              -27.0               -27.0  \n",
       "35               20.0                20.0  \n",
       "37              -22.0               -22.0  \n",
       "39                NaN                 NaN  \n",
       "41              -51.0               -51.0  \n",
       "42                NaN                 NaN  \n",
       "44               43.0                43.0  \n",
       "46                NaN                 NaN  \n",
       "51                3.0                 3.0  \n",
       "52              -20.0               -20.0  \n",
       "53                2.0                 2.0  \n",
       "57                7.0                 7.0  \n",
       "58              -59.0               -59.0  \n",
       "59              -29.0               -29.0  \n",
       "60              -16.0               -16.0  \n",
       "61                NaN                 NaN  \n",
       "62               51.0                51.0  \n",
       "67               -1.0                -1.0  \n",
       "68              -15.0               -15.0  \n",
       "72              -12.0               -12.0  \n",
       "73              -48.0               -48.0  \n",
       "\n",
       "[42 rows x 516 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_info[~((game_info['ra_allowed_defensiveRebounds_w1_home'].isna()) & (game_info['ra_allowed_defensiveRebounds_w1_home'].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03eca27aa3e5b0c2bf98348f6751bc7dc08663828d24c367008019d5f5934307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
