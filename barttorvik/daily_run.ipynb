{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAILY GAME IDS\n",
    "\n",
    "- grabs games based on date\n",
    "- date, time, home, away, neutral, conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "DATE = \"20251105\"\n",
    "csv_files = glob.glob(\"data/boxscores/game-info-2026/*.csv\")\n",
    "combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "combined_df = combined_df.merge(team_map, left_on=\"home_team\", right_on=\"espn\", how=\"left\").merge(team_map, left_on=\"away_team\", right_on=\"espn\", how=\"left\")\n",
    "\n",
    "combined_df['home'] = combined_df['team_x']\n",
    "combined_df['away'] = combined_df['team_y']\n",
    "\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "combined_df['date_key'] = pd.to_numeric(combined_df['date'], errors='coerce').astype('Int64')\n",
    "\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "combined_df['date_key'] = pd.to_numeric(combined_df['date'], errors='coerce').astype('Int64')\n",
    "conferences = pd.concat([pd.read_csv(\"s3://collegebasketballinsiders/daily-torvik/2024/barttorvik_20240312.csv\")[[\"Team\", \"Conf\"]], pd.read_csv(\"s3://collegebasketballinsiders/daily-torvik/2025/barttorvik_20250318.csv\")[[\"Team\", \"Conf\"]], pd.read_csv(\"barttorvik_2026_all.csv\")[[\"Team\", \"Conf\"]]], axis=0)\n",
    "conferences = conferences[conferences['Team'] != \"Team\"]\n",
    "conferences['Team'] = conferences['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "conferences = conferences.drop_duplicates(subset=\"Team\")\n",
    "\n",
    "# --- normalize team names (strip seeds/suffixes) ---\n",
    "name_pat = r'^([A-Za-z\\s.&\\'-]+)'\n",
    "def clean_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    m = re.match(name_pat, str(s))\n",
    "    base = m.group(1) if m else str(s)\n",
    "    return re.sub(r'\\s+', ' ', base).strip()\n",
    "\n",
    "combined_df['home_key'] = combined_df['home'].map(clean_team)\n",
    "combined_df['away_key'] = combined_df['away'].map(clean_team)\n",
    "conferences['team_key'] = conferences['Team'].map(clean_team)\n",
    "\n",
    "right = conferences.drop_duplicates(['team_key']).copy()\n",
    "\n",
    "# --- Build HOME version of the right table ---\n",
    "home_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_home = right.rename(columns={'team_key': 'home_key', **{c: f'{c}_home' for c in home_cols}})\n",
    "\n",
    "# --- Merge HOME ---\n",
    "combined_df = combined_df.merge(\n",
    "    torvik_home,\n",
    "    on='home_key',\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# --- Build AWAY version of the right table ---\n",
    "away_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_away = right.rename(columns={'team_key': 'away_key', **{c: f'{c}_away' for c in away_cols}})\n",
    "\n",
    "# --- Merge AWAY ---\n",
    "combined_df = combined_df.merge(\n",
    "    torvik_away,\n",
    "    on='away_key',\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "combined_df['season'] = 2026\n",
    "combined_df['neutral_site'] = np.where(combined_df['neutral_site'] == True, 1, 0)\n",
    "\n",
    "combined_df = combined_df[[\"game_id\", \"date\", \"date_key\", \"date_utc\", \"time_utc\", \"neutral_site\", \"home\", \"away\", \"Conf_home\", \"Conf_away\"]]\n",
    "combined_df.columns = [\"game_id\", \"date\", \"date_key\", \"date_utc\", \"time_utc\", \"neutral_site\", \"home\", \"away\", \"conf_home\", \"conf_away\"]\n",
    "\n",
    "csv_files = glob.glob(f\"daily-box-score-ids/{DATE}/*.csv\")\n",
    "game_id_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "game_ids = list(game_id_df['game_id'])\n",
    "combined_df[combined_df['game_id'].isin(game_ids)].to_csv(\"daily-games/daily.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEASON GAME INFORMATION AND TEAM STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/game-info-2026/*.csv\")\n",
    "combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "combined_df = combined_df.merge(team_map, left_on=\"home_team\", right_on=\"espn\", how=\"left\").merge(team_map, left_on=\"away_team\", right_on=\"espn\", how=\"left\")\n",
    "\n",
    "combined_df['home'] = combined_df['team_x']\n",
    "combined_df['away'] = combined_df['team_y']\n",
    "\n",
    "combined_df = combined_df.dropna(subset=\"home\").dropna(subset=\"away\").dropna(subset=\"home_1h\")\n",
    "combined_df = combined_df[['game_id', 'date_utc', 'time_utc', 'neutral_site', 'home',\n",
    "       'away', 'home_1h', 'away_1h', 'home_2h', 'away_2h', 'home_score',\n",
    "       'away_score']]\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/team-stats-2026/*.csv\")\n",
    "team_combined_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "combined_df.sort_values(\"date_utc\")\n",
    "\n",
    "df = team_combined_df.sort_values(['displayOrder'])\n",
    "\n",
    "# create a helper column to pair home/away rows by game id\n",
    "# (if you don't already have a game_id column)\n",
    "# Split into home and away\n",
    "home_df = df[df['homeAway'] == 'home'].copy()\n",
    "away_df = df[df['homeAway'] == 'away'].copy()\n",
    "\n",
    "# Columns we don't want duplicated (they’ll be renamed anyway)\n",
    "cols_to_remove = ['homeAway', 'displayOrder', 'abbreviation', 'team_id']\n",
    "\n",
    "# Rename columns to indicate home/away\n",
    "home_df = home_df.drop(columns=cols_to_remove).add_suffix('_home')\n",
    "away_df = away_df.drop(columns=cols_to_remove).add_suffix('_away')\n",
    "\n",
    "# Merge back together on the shared game_id\n",
    "# (keep original game_id)\n",
    "final_df = pd.merge(\n",
    "    home_df,\n",
    "    away_df,\n",
    "    left_on='game_id_home',\n",
    "    right_on='game_id_away',\n",
    "    suffixes=('', ''),\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Keep just one copy of game_id\n",
    "final_df['game_id'] = final_df['game_id_home']\n",
    "final_df = final_df.drop(columns=['game_id_home', 'game_id_away'])\n",
    "\n",
    "# Optional: reorder columns to have game_id first\n",
    "cols = ['game_id'] + [c for c in final_df.columns if c != 'game_id']\n",
    "final_df = final_df[cols]\n",
    "\n",
    "final_df = final_df[['game_id', 'assists_home', 'defensiveRebounds_home', 'freeThrowPct_home',\n",
    "       'threePointFieldGoalsMade-threePointFieldGoalsAttempted_home',\n",
    "       'fouls_home', 'totalRebounds_home', 'threePointFieldGoalPct_home',\n",
    "       'teamTurnovers_home', 'pointsInPaint_home', 'technicalFouls_home',\n",
    "       'totalTechnicalFouls_home', 'largestLead_home',\n",
    "       'offensiveRebounds_home', 'fieldGoalPct_home',\n",
    "       'totalTurnovers_home', 'turnoverPoints_home', 'flagrantFouls_home',\n",
    "       'freeThrowsMade-freeThrowsAttempted_home', 'steals_home',\n",
    "       'fieldGoalsMade-fieldGoalsAttempted_home', 'blocks_home',\n",
    "       'fastBreakPoints_home', 'turnovers_home',  'assists_away',\n",
    "       'defensiveRebounds_away', 'freeThrowPct_away',\n",
    "       'threePointFieldGoalsMade-threePointFieldGoalsAttempted_away',\n",
    "       'fouls_away', 'totalRebounds_away', 'threePointFieldGoalPct_away',\n",
    "       'teamTurnovers_away', 'pointsInPaint_away', 'technicalFouls_away',\n",
    "       'totalTechnicalFouls_away', 'largestLead_away',\n",
    "       'offensiveRebounds_away', 'fieldGoalPct_away',\n",
    "       'totalTurnovers_away', 'turnoverPoints_away', 'flagrantFouls_away',\n",
    "       'freeThrowsMade-freeThrowsAttempted_away', 'steals_away',\n",
    "       'fieldGoalsMade-fieldGoalsAttempted_away', 'blocks_away',\n",
    "       'fastBreakPoints_away', 'turnovers_away']]\n",
    "\n",
    "combined_df = combined_df.merge(final_df, on=\"game_id\")\n",
    "\n",
    "csv_files = glob.glob(\"data/boxscores/officials-2026/*.csv\")\n",
    "officials_df = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# create a rank/order number per game_id\n",
    "officials_df['official_number'] = officials_df.groupby('game_id').cumcount() + 1\n",
    "\n",
    "# pivot to wide format\n",
    "flat_officials = (\n",
    "    officials_df.pivot(index='game_id', columns='official_number', values='official_name')\n",
    "    .rename(columns=lambda x: f'official_{x}')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "flat_officials = flat_officials[[\"game_id\", \"official_1\", \"official_2\", \"official_3\"]]\n",
    "\n",
    "combined_df = combined_df.merge(flat_officials, on=\"game_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "team_map = pd.read_csv(\"data/teams/map.csv\")[[\"team\", \"espn\"]]\n",
    "\n",
    "game_df = combined_df\n",
    "game_df['date'] = pd.to_datetime(game_df['date_utc']).dt.strftime('%Y%m%d')\n",
    "game_df['home_margin'] = game_df['home_score'] - game_df['away_score']\n",
    "game_df['away_margin'] = game_df['away_score'] - game_df['home_score']\n",
    "\n",
    "csv_files_2026 = glob.glob(\"daily_csvs_2026/*.csv\")\n",
    "daily_torvik_2026_df = pd.concat((pd.read_csv(f) for f in csv_files_2026), ignore_index=True)\n",
    "daily_torvik_2026_df = daily_torvik_2026_df[daily_torvik_2026_df['Team'] != \"Team\"]\n",
    "daily_torvik_2026_df['Team'] = daily_torvik_2026_df['Team'].str.extract(r'^([A-Za-z\\s.&]+)')[0].str.strip()\n",
    "daily_torvik_2026_df['WAB'] = daily_torvik_2026_df['WAB'].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n",
    "daily_torvik_2026_df['season'] = 2026\n",
    "daily_torvik_2026_df = daily_torvik_2026_df[['season','Date', 'Team', 'Rk', 'Conf', 'G', 'AdjOE', 'AdjDE', 'Barthag',\n",
    "       'EFG%', 'EFGD%', 'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P%',\n",
    "       '2P%D', '3P%', '3P%D', '3PR', '3PRD', 'Adj T.', 'WAB']].sort_values([\"Date\",\"Team\"], ascending=True)\n",
    "daily_torvik_2026_df.columns = ['season', 'date', 'team', 'rank', 'conf', 'games', 'adj_off_eff', 'adj_def_eff', 'barthag',\n",
    "       'efg_pct', 'efgd_pct', 'tor', 'tord', 'orb', 'drb', 'ftr', 'ftrd', 'two_pt_pct',\n",
    "       'two_pt_def_pct', 'three_pt_pct', 'three_pt_def_pct', 'three_pt_rt', 'three_pt_def_rt', 'adj_tempo', 'wab']\n",
    "\n",
    "# assert len(set(daily_torvik_2026_df['team']) - set(team_map['team'])) == 0\n",
    "\n",
    "daily_torvik_df = daily_torvik_2026_df\n",
    "\n",
    "\n",
    "import re\n",
    "game_df['date_key'] = pd.to_numeric(game_df['date'], errors='coerce').astype('Int64')\n",
    "daily_torvik_df['date_key'] = pd.to_numeric(daily_torvik_df['date'], errors='coerce').astype('Int64')\n",
    "\n",
    "# --- normalize team names (strip seeds/suffixes) ---\n",
    "name_pat = r'^([A-Za-z\\s.&\\'-]+)'\n",
    "def clean_team(s):\n",
    "    if pd.isna(s): return s\n",
    "    m = re.match(name_pat, str(s))\n",
    "    base = m.group(1) if m else str(s)\n",
    "    return re.sub(r'\\s+', ' ', base).strip()\n",
    "\n",
    "game_df['home_key'] = game_df['home'].map(clean_team)\n",
    "game_df['away_key'] = game_df['away'].map(clean_team)\n",
    "daily_torvik_df['team_key'] = daily_torvik_df['team'].map(clean_team)\n",
    "\n",
    "right = daily_torvik_df.drop_duplicates(['date_key', 'team_key']).copy()\n",
    "\n",
    "# --- Build HOME version of the right table ---\n",
    "home_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_home = right.rename(columns={'team_key': 'home_key', **{c: f'{c}_home' for c in home_cols}})\n",
    "\n",
    "# --- Merge HOME ---\n",
    "merged_df = game_df.merge(\n",
    "    torvik_home,\n",
    "    on=['date_key', 'home_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "# --- Build AWAY version of the right table ---\n",
    "away_cols = [c for c in right.columns if c not in ['date_key', 'team_key']]\n",
    "torvik_away = right.rename(columns={'team_key': 'away_key', **{c: f'{c}_away' for c in away_cols}})\n",
    "\n",
    "# --- Merge AWAY ---\n",
    "merged_df = merged_df.merge(\n",
    "    torvik_away,\n",
    "    on=['date_key', 'away_key'],\n",
    "    how='left',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "\n",
    "merged_df['season'] = 2026\n",
    "merged_df['neutral_site'] = np.where(merged_df['neutral_site'] == True, 1, 0)\n",
    "\n",
    "merged_df = merged_df[[\n",
    "    'game_id',\n",
    "    'season',\n",
    "    'date',\n",
    "    'date_utc',\n",
    "    'time_utc',\n",
    "    'neutral_site',\n",
    "    'home',\n",
    "    'away',\n",
    "    'home_1h',\n",
    "    'away_1h',\n",
    "    'home_2h',\n",
    "    'away_2h',\n",
    "    'home_score',\n",
    "    'away_score',\n",
    "    'home_margin',\n",
    "    'away_margin',\n",
    "    'assists_home',\n",
    "    'fouls_home',\n",
    "    'technicalFouls_home',\n",
    "    'flagrantFouls_home',\n",
    "    'totalRebounds_home',\n",
    "    'offensiveRebounds_home',\n",
    "    'defensiveRebounds_home',\n",
    "    'pointsInPaint_home',\n",
    "    'turnovers_home',\n",
    "    'turnoverPoints_home',\n",
    "    'steals_home',\n",
    "    'blocks_home',\n",
    "    'fastBreakPoints_home',\n",
    "    'assists_away',\n",
    "    'fouls_away',\n",
    "    'technicalFouls_away',\n",
    "    'flagrantFouls_away',\n",
    "    'totalRebounds_away',\n",
    "    'offensiveRebounds_away',\n",
    "    'defensiveRebounds_away',\n",
    "    'pointsInPaint_away',\n",
    "    'turnovers_away',\n",
    "    'turnoverPoints_away',\n",
    "    'steals_away',\n",
    "    'blocks_away',\n",
    "    'fastBreakPoints_away',\n",
    "    'official_1',\n",
    "    'official_2',\n",
    "    'official_3',  \n",
    "    'rank_home',\n",
    "    'conf_home',\n",
    "    'games_home',\n",
    "    'adj_off_eff_home',\n",
    "    'adj_def_eff_home',\n",
    "    'barthag_home',\n",
    "    'efg_pct_home',\n",
    "    'efgd_pct_home',\n",
    "    'tor_home',\n",
    "    'tord_home',\n",
    "    'orb_home',\n",
    "    'drb_home',\n",
    "    'ftr_home',\n",
    "    'ftrd_home',\n",
    "    'two_pt_pct_home',\n",
    "    'two_pt_def_pct_home',\n",
    "    'three_pt_pct_home',\n",
    "    'three_pt_def_pct_home',\n",
    "    'three_pt_rt_home',\n",
    "    'three_pt_def_rt_home',\n",
    "    'adj_tempo_home',\n",
    "    'wab_home',\n",
    "    'rank_away',\n",
    "    'conf_away',\n",
    "    'games_away',\n",
    "    'adj_off_eff_away',\n",
    "    'adj_def_eff_away',\n",
    "    'barthag_away',\n",
    "    'efg_pct_away',\n",
    "    'efgd_pct_away',\n",
    "    'tor_away',\n",
    "    'tord_away',\n",
    "    'orb_away',\n",
    "    'drb_away',\n",
    "    'ftr_away',\n",
    "    'ftrd_away',\n",
    "    'two_pt_pct_away',\n",
    "    'two_pt_def_pct_away',\n",
    "    'three_pt_pct_away',\n",
    "    'three_pt_def_pct_away',\n",
    "    'three_pt_rt_away',\n",
    "    'three_pt_def_rt_away',\n",
    "    'adj_tempo_away',\n",
    "    'wab_away']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SET 1 USING DAILY.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_time_officials_conference.py\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from typing import Dict, Optional, Iterable, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Configuration ----\n",
    "OFFICIAL_COLS = ['official_1', 'official_2', 'official_3']\n",
    "LOCAL_TZ = 'America/New_York'  # Eastern time\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _ensure_date_key_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize YYYYMMDD to 8-char string from any input series.\"\"\"\n",
    "    return s.astype(str).str.extract(r'(\\d{8})')[0]\n",
    "\n",
    "def _build_tipoff_utc(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build timezone-aware UTC datetime from (date_key + time_utc like '21:00Z').\n",
    "    Requires: 'date_key' (YYYYMMDD) and 'time_utc' ('HH:MMZ' or 'HH:MM').\n",
    "    \"\"\"\n",
    "    if 'date_utc' not in df.columns:\n",
    "        raise KeyError(\"Expected 'date_key' (YYYYMMDD).\")\n",
    "    if 'time_utc' not in df.columns:\n",
    "        raise KeyError(\"Expected 'time_utc' like '21:00Z' or '21:00'.\")\n",
    "\n",
    "    # use date_key (not 'date'); coerce invalids to NaT\n",
    "    date_key = _ensure_date_key_str(df['date'])\n",
    "    t = df['time_utc'].astype(str).str.strip()\n",
    "    t = np.where(t.str.endswith('Z'), t, t + 'Z')  # ensure trailing Z\n",
    "    iso_date = pd.to_datetime(date_key, format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    iso = iso_date + ' ' + t\n",
    "    tipoff_utc = pd.to_datetime(iso, utc=True, errors='coerce', infer_datetime_format=True)\n",
    "    return tipoff_utc\n",
    "\n",
    "def _time_features_from_dt(dt: pd.Series, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From a timezone-aware datetime series, produce:\n",
    "      - {prefix}_hour, {prefix}_minute, {prefix}_second\n",
    "      - {prefix}_seconds_since_midnight\n",
    "      - {prefix}_hour_sin, {prefix}_hour_cos (cyclical)\n",
    "    \"\"\"\n",
    "    out = pd.DataFrame(index=dt.index)\n",
    "    out[f'{prefix}_hour'] = dt.dt.hour.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_minute'] = dt.dt.minute.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_second'] = dt.dt.second.fillna(0).astype('int16')\n",
    "    out[f'{prefix}_seconds_since_midnight'] = (\n",
    "        out[f'{prefix}_hour'] * 3600 + out[f'{prefix}_minute'] * 60 + out[f'{prefix}_second']\n",
    "    ).astype('int32')\n",
    "\n",
    "    two_pi = 2 * np.pi\n",
    "    out[f'{prefix}_hour_sin'] = np.sin(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    out[f'{prefix}_hour_cos'] = np.cos(two_pi * out[f'{prefix}_hour'] / 24.0)\n",
    "    return out\n",
    "\n",
    "def _add_day_flags(local_dt: pd.Series, base_df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Day-of-week flags on LOCAL time:\n",
    "      - {prefix}_is_weekend (Sat/Sun)\n",
    "      - {prefix}_is_primetime (18:00–22:59)\n",
    "      - {prefix}_daypart_* one-hots: morning(5–11), afternoon(12–16), evening(17–21), late(other)\n",
    "    \"\"\"\n",
    "    out = base_df.copy()\n",
    "    dow = local_dt.dt.dayofweek  # Mon=0..Sun=6\n",
    "    out[f'{prefix}_is_weekend'] = dow.isin([5, 6]).fillna(False).astype('int8')\n",
    "\n",
    "    hour = local_dt.dt.hour.fillna(0).astype(int)\n",
    "    out[f'{prefix}_is_primetime'] = ((hour >= 18) & (hour <= 22)).astype('int8')\n",
    "\n",
    "    def _daypart(h):\n",
    "        if 5 <= h <= 11:  return 'morning'\n",
    "        if 12 <= h <= 16: return 'afternoon'\n",
    "        if 17 <= h <= 21: return 'evening'\n",
    "        return 'late'\n",
    "\n",
    "    dp = hour.map(_daypart).astype('category')\n",
    "    dummies = pd.get_dummies(dp, prefix=f'{prefix}_daypart', dtype='int8')\n",
    "    out = pd.concat([out, dummies], axis=1)\n",
    "    return out\n",
    "\n",
    "# ---------- Transform (apply saved maps) ----------\n",
    "def transform_officials_with_map(df: pd.DataFrame, mapping: Dict[str, int],\n",
    "                                 official_cols: Iterable[str] = OFFICIAL_COLS) -> pd.DataFrame:\n",
    "    \"\"\"Apply the shared mapping to each official* column, creating *_code columns.\"\"\"\n",
    "    out = df.copy()\n",
    "    unk = mapping.get('UNK', 0)\n",
    "    for c in official_cols:\n",
    "        if c in out.columns:\n",
    "            s = out[c].astype('string')\n",
    "            out[f'{c}_code'] = s.map(mapping).fillna(unk).astype('int32')\n",
    "        else:\n",
    "            out[f'{c}_code'] = unk\n",
    "    return out\n",
    "\n",
    "def transform_with_map(series: pd.Series, mapping: Dict[str, int], fill_value: str = 'UNK') -> pd.Series:\n",
    "    \"\"\"Transform using a prefit mapping, unknowns go to code for fill_value (default 0).\"\"\"\n",
    "    return series.astype('string').fillna(fill_value).map(mapping).fillna(mapping.get(fill_value, 0)).astype('int32')\n",
    "\n",
    "# ---------- Public Inference Entry ----------\n",
    "def load_enc_maps(path: str) -> Dict[str, Dict[str, int]]:\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def build_time_officials_conference_features_inference(\n",
    "    df: pd.DataFrame,\n",
    "    enc_maps: Dict[str, Dict[str, int]],\n",
    "    *,\n",
    "    add_et_features: bool = True,\n",
    "    make_conference_dummies: bool = False\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, int]]]:\n",
    "    \"\"\"\n",
    "    INFERENCE version:\n",
    "      - Uses prefit maps in `enc_maps` to transform officials + conferences\n",
    "      - Builds UTC/ET time features + flags\n",
    "      - Does NOT refit any encoder\n",
    "    Returns: (features_df, enc_maps) for convenience\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Ensure date_key exists for time parsing\n",
    "    if 'date_key' not in out.columns:\n",
    "        if 'date' in out.columns:\n",
    "            out['date_key'] = _ensure_date_key_str(out['date'])\n",
    "        else:\n",
    "            raise KeyError(\"Expected 'date' or 'date_key' in inference dataframe.\")\n",
    "\n",
    "    # Build UTC time + time features\n",
    "    out['tipoff_utc'] = _build_tipoff_utc(out)\n",
    "    utc_feats = _time_features_from_dt(out['tipoff_utc'], prefix='utc')\n",
    "    out = pd.concat([out, utc_feats], axis=1)\n",
    "\n",
    "    # Local (ET) features + day flags\n",
    "    if add_et_features:\n",
    "        tipoff_et = out['tipoff_utc'].dt.tz_convert(LOCAL_TZ)\n",
    "        et_feats = _time_features_from_dt(tipoff_et, prefix='et')\n",
    "        out = pd.concat([out, et_feats], axis=1)\n",
    "        out = _add_day_flags(tipoff_et, out, prefix='et')\n",
    "\n",
    "    # Officials (shared map)\n",
    "    official_map = enc_maps.get('official_map', {'UNK': 0})\n",
    "    out = transform_officials_with_map(out, official_map, OFFICIAL_COLS)\n",
    "\n",
    "    # Conferences\n",
    "    if 'conf_home' in out.columns:\n",
    "        conf_home_map = enc_maps.get('conf_home_map', {'UNK': 0})\n",
    "        out['conf_home_code'] = transform_with_map(out['conf_home'], conf_home_map)\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_home'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_home', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    if 'conf_away' in out.columns:\n",
    "        conf_away_map = enc_maps.get('conf_away_map', {'UNK': 0})\n",
    "        out['conf_away_code'] = transform_with_map(out['conf_away'], conf_away_map)\n",
    "        if make_conference_dummies:\n",
    "            dummies = pd.get_dummies(out['conf_away'].astype('string').fillna('UNK'),\n",
    "                                     prefix='conf_away', dtype='int8')\n",
    "            out = pd.concat([out, dummies], axis=1)\n",
    "\n",
    "    return out, enc_maps\n",
    "\n",
    "# ---------- Optional: align to training feature set ----------\n",
    "def align_to_training_features(df_features: pd.DataFrame, train_feature_cols: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reindex to the exact training feature set:\n",
    "      - add any missing columns (filled with 0),\n",
    "      - drop any extra columns,\n",
    "      - keep the same ordering as training.\n",
    "    Ensures numeric dtype for all features.\n",
    "    \"\"\"\n",
    "    X = df_features.reindex(columns=train_feature_cols, fill_value=0)\n",
    "    for c in X.columns:\n",
    "        if not np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce').fillna(0)\n",
    "    return X\n",
    "\n",
    "enc_maps = load_enc_maps(\"data/train/enc_maps.json\")\n",
    "\n",
    "# 2) Apply to new games dataframe (must have: 'date' or 'date_key', and 'time_utc')\n",
    "features_1, _ = build_time_officials_conference_features_inference(\n",
    "    pd.read_csv(\"daily-games/daily.csv\"), enc_maps,\n",
    "    add_et_features=True,\n",
    "    make_conference_dummies=True\n",
    ")\n",
    "features_1[[\"et_daypart_afternoon\",'et_daypart_morning']] = 0\n",
    "features_1 = features_1[['game_id', 'utc_seconds_since_midnight', 'utc_hour_sin', 'utc_hour_cos',\n",
    "       'et_hour', 'et_minute', 'et_second', 'et_seconds_since_midnight',\n",
    "       'et_hour_sin', 'et_hour_cos', 'et_is_weekend', 'et_is_primetime',\n",
    "       'et_daypart_afternoon', 'et_daypart_evening', 'et_daypart_late',\n",
    "       'et_daypart_morning', 'official_1_code', 'official_2_code',\n",
    "       'official_3_code', 'conf_home_code', 'conf_away_code']]\n",
    "\n",
    "\n",
    "\n",
    "assert len(set(list(features_1.columns)) - set(['game_id', 'utc_seconds_since_midnight', 'utc_hour_sin', 'utc_hour_cos',\n",
    "       'et_hour', 'et_minute', 'et_second', 'et_seconds_since_midnight',\n",
    "       'et_hour_sin', 'et_hour_cos', 'et_is_weekend', 'et_is_primetime',\n",
    "       'et_daypart_afternoon', 'et_daypart_evening', 'et_daypart_late',\n",
    "       'et_daypart_morning', 'official_1_code', 'official_2_code',\n",
    "       'official_3_code', 'conf_home_code', 'conf_away_code'])) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SET 2/3 USING 2026 GAME INFORMATION AND TORVVIK RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- base dataframe ---\n",
    "df = merged_df[['game_id', 'season', 'date', 'date_utc', 'time_utc',\n",
    "       'neutral_site', 'home', 'away', 'home_1h', 'away_1h', 'home_2h',\n",
    "       'away_2h', 'home_score', 'away_score', 'home_margin',\n",
    "       'away_margin','rank_home', 'games_home',\n",
    "       'adj_off_eff_home', 'adj_def_eff_home', 'barthag_home',\n",
    "       'efg_pct_home', 'efgd_pct_home', 'tor_home', 'tord_home',\n",
    "       'orb_home', 'drb_home', 'ftr_home', 'ftrd_home', 'two_pt_pct_home',\n",
    "       'two_pt_def_pct_home', 'three_pt_pct_home',\n",
    "       'three_pt_def_pct_home', 'three_pt_rt_home',\n",
    "       'three_pt_def_rt_home', 'adj_tempo_home', 'wab_home', 'rank_away',\n",
    "       'games_away', 'adj_off_eff_away', 'adj_def_eff_away',\n",
    "       'barthag_away', 'efg_pct_away', 'efgd_pct_away', 'tor_away',\n",
    "       'tord_away', 'orb_away', 'drb_away', 'ftr_away', 'ftrd_away',\n",
    "       'two_pt_pct_away', 'two_pt_def_pct_away', 'three_pt_pct_away',\n",
    "       'three_pt_def_pct_away', 'three_pt_rt_away',\n",
    "       'three_pt_def_rt_away', 'adj_tempo_away', 'wab_away']].copy()\n",
    "\n",
    "# --- 1) datetime for chronological sort (UTC preferred if available) ---\n",
    "if 'date_utc' in df.columns and df['date_utc'].notna().any():\n",
    "    if 'time_utc' in df.columns:\n",
    "        df['game_dt'] = pd.to_datetime(\n",
    "            df['date_utc'].astype(str).str.strip() + ' ' +\n",
    "            df['time_utc'].fillna('00:00:00').astype(str).str.strip(),\n",
    "            errors='coerce', utc=True\n",
    "        )\n",
    "    else:\n",
    "        df['game_dt'] = pd.to_datetime(df['date_utc'], errors='coerce', utc=True)\n",
    "else:\n",
    "    df['game_dt'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# --- 2) bases from *_home / *_away ---\n",
    "suffix_cols = [c for c in df.columns if c.endswith('_home') or c.endswith('_away')]\n",
    "bases = sorted({c.rsplit('_', 1)[0] for c in suffix_cols})\n",
    "\n",
    "# --- 3) map columns to team/opp perspective ---\n",
    "home_to_team = {f'{b}_home': b for b in bases}\n",
    "away_to_team = {f'{b}_away': b for b in bases}\n",
    "home_to_opp  = {f'{b}_away': f'opp_{b}' for b in bases}\n",
    "away_to_opp  = {f'{b}_home': f'opp_{b}' for b in bases}\n",
    "\n",
    "id_cols = ['game_id','season','date','game_dt','neutral_site']\n",
    "id_cols = [c for c in id_cols if c in df.columns]\n",
    "\n",
    "home_view = df[id_cols + ['home','away'] + suffix_cols].copy()\n",
    "home_view = home_view.rename(columns={'home':'team','away':'opponent'})\n",
    "home_view = home_view.rename(columns={**home_to_team, **home_to_opp})\n",
    "home_view['is_home'] = 1\n",
    "\n",
    "away_view = df[id_cols + ['home','away'] + suffix_cols].copy()\n",
    "away_view = away_view.rename(columns={'away':'team','home':'opponent'})\n",
    "away_view = away_view.rename(columns={**away_to_team, **away_to_opp})\n",
    "away_view['is_home'] = 0\n",
    "\n",
    "team_games = pd.concat([home_view, away_view], ignore_index=True, sort=False)\n",
    "team_games = team_games.sort_values(['team','season','game_dt','game_id'], ignore_index=True)\n",
    "\n",
    "# --- 4) coerce numeric fields used below ---\n",
    "def _to_num(s: pd.Series) -> pd.Series:\n",
    "    if s.dtype == 'O':\n",
    "        s = s.astype(str).str.strip().str.rstrip('%')\n",
    "    return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "numeric_needed = set()\n",
    "for b in bases:\n",
    "    if b in team_games.columns: numeric_needed.add(b)\n",
    "    ob = f'opp_{b}'\n",
    "    if ob in team_games.columns: numeric_needed.add(ob)\n",
    "if 'opp_rank' in team_games.columns: numeric_needed.add('opp_rank')\n",
    "\n",
    "if numeric_needed:\n",
    "    team_games[list(numeric_needed)] = team_games[list(numeric_needed)].apply(_to_num)\n",
    "\n",
    "# --- 5) cumulative opponent rank (inclusive + \"pre\" if you still use it) ---\n",
    "if 'opp_rank' in team_games.columns:\n",
    "    g = team_games.groupby(['team','season'], dropna=False)['opp_rank']\n",
    "    team_games['opp_rank_cummean_incl'] = g.cumsum() / (g.cumcount() + 1)  # includes current\n",
    "    cs = g.cumsum()\n",
    "    cnt = g.cumcount()\n",
    "    team_games['opp_rank_cummean_pre'] = cs.shift(1) / cnt.replace(0, np.nan)  # prior-only\n",
    "\n",
    "# --- 6) take the latest played row per team-season ---\n",
    "latest = (\n",
    "    team_games\n",
    "    .sort_values(['team','season','game_dt','game_id'])\n",
    "    .groupby(['team','season'], as_index=False, sort=False)\n",
    "    .tail(1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- 7) rename CURRENT values to match training names (lag1_*) ---\n",
    "team_feature_cols = [c for c in bases if c in latest.columns]\n",
    "opp_feature_cols  = [f'opp_{b}' for b in bases if f'opp_{b}' in latest.columns]\n",
    "\n",
    "rename_map = {}\n",
    "for c in team_feature_cols:\n",
    "    rename_map[c] = f'lag1_{c}'\n",
    "for c in opp_feature_cols:\n",
    "    rename_map[c] = f'lag1_{c}'\n",
    "\n",
    "latest_renamed = latest.rename(columns=rename_map)\n",
    "\n",
    "# --- 8) build features_2 with the exact columns you listed ---\n",
    "wanted_cols = ['game_id','team','opponent',\n",
    "    'lag1_adj_def_eff','lag1_adj_off_eff','lag1_adj_tempo','lag1_barthag',\n",
    "    'lag1_drb','lag1_efg_pct','lag1_efgd_pct','lag1_ftr','lag1_ftrd',\n",
    "    'lag1_games','lag1_orb','lag1_rank','lag1_three_pt_def_pct',\n",
    "    'lag1_three_pt_def_rt','lag1_three_pt_pct','lag1_three_pt_rt',\n",
    "    'lag1_tor','lag1_tord','lag1_two_pt_def_pct','lag1_two_pt_pct','lag1_wab',\n",
    "    'lag1_opp_adj_def_eff','lag1_opp_adj_off_eff','lag1_opp_adj_tempo',\n",
    "    'lag1_opp_barthag','lag1_opp_drb','lag1_opp_efg_pct','lag1_opp_efgd_pct',\n",
    "    'lag1_opp_ftr','lag1_opp_ftrd','lag1_opp_games','lag1_opp_orb',\n",
    "    'lag1_opp_rank','lag1_opp_three_pt_def_pct','lag1_opp_three_pt_def_rt',\n",
    "    'lag1_opp_three_pt_pct','lag1_opp_three_pt_rt','lag1_opp_tor',\n",
    "    'lag1_opp_tord','lag1_opp_two_pt_def_pct','lag1_opp_two_pt_pct',\n",
    "    'lag1_opp_wab',\n",
    "    'opp_rank_cummean_incl','opp_rank_cummean_pre'\n",
    "]\n",
    "\n",
    "# keep only those that exist (some sources may lack a few)\n",
    "final_cols = [c for c in wanted_cols if c in latest_renamed.columns]\n",
    "features_2 = latest_renamed[final_cols].copy()\n",
    "assert len(set(list(features_2.columns)) - set(['game_id', 'team', 'opponent',\n",
    "       'lag1_adj_def_eff', 'lag1_adj_off_eff',\n",
    "       'lag1_adj_tempo', 'lag1_barthag', 'lag1_drb', 'lag1_efg_pct',\n",
    "       'lag1_efgd_pct', 'lag1_ftr', 'lag1_ftrd', 'lag1_games', 'lag1_orb',\n",
    "       'lag1_rank', 'lag1_three_pt_def_pct', 'lag1_three_pt_def_rt',\n",
    "       'lag1_three_pt_pct', 'lag1_three_pt_rt', 'lag1_tor', 'lag1_tord',\n",
    "       'lag1_two_pt_def_pct', 'lag1_two_pt_pct', 'lag1_wab',\n",
    "       'lag1_opp_adj_def_eff', 'lag1_opp_adj_off_eff',\n",
    "       'lag1_opp_adj_tempo', 'lag1_opp_barthag', 'lag1_opp_drb',\n",
    "       'lag1_opp_efg_pct', 'lag1_opp_efgd_pct', 'lag1_opp_ftr',\n",
    "       'lag1_opp_ftrd', 'lag1_opp_games', 'lag1_opp_orb', 'lag1_opp_rank',\n",
    "       'lag1_opp_three_pt_def_pct', 'lag1_opp_three_pt_def_rt',\n",
    "       'lag1_opp_three_pt_pct', 'lag1_opp_three_pt_rt', 'lag1_opp_tor',\n",
    "       'lag1_opp_tord', 'lag1_opp_two_pt_def_pct', 'lag1_opp_two_pt_pct',\n",
    "       'lag1_opp_wab', 'opp_rank_cummean_incl', 'opp_rank_cummean_pre'])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_cbb_features_inference(raw_df, windows=(1,3,5,10), ewm_halflife=5, today_utc=None):\n",
    "    \"\"\"\n",
    "    Inference feature builder.\n",
    "\n",
    "    Only change from your previous version:\n",
    "      - Rest days:\n",
    "          * Historical per-game gaps (for rolling features) stay the same.\n",
    "          * The final 'rest_days' for the latest snapshot per team/season is\n",
    "            computed as (today_utc - last_completed_game_dt).days, so teams that\n",
    "            played a few days ago won't default to 7 anymore.\n",
    "\n",
    "    Args:\n",
    "        raw_df: wide game-level dataframe with *_home / *_away stats\n",
    "        windows: rolling windows\n",
    "        ewm_halflife: half-life for EWM\n",
    "        today_utc: pd.Timestamp (tz-aware, UTC). If None, uses current UTC time.\n",
    "    \"\"\"\n",
    "    df = raw_df.copy()\n",
    "\n",
    "    # --- choose \"today\" in UTC (tz-aware) ---\n",
    "    if today_utc is None:\n",
    "        # use current UTC\n",
    "        today_utc = pd.Timestamp.utcnow()\n",
    "\n",
    "    # --- 0) Build a proper datetime (UTC if you have date_utc/time_utc) ---\n",
    "    if 'date_utc' in df.columns and df['date_utc'].notna().any():\n",
    "        if 'time_utc' in df.columns:\n",
    "            df['game_dt'] = pd.to_datetime(\n",
    "                df['date_utc'].astype(str).str.strip() + ' ' +\n",
    "                df['time_utc'].fillna('00:00:00').astype(str).str.strip(),\n",
    "                errors='coerce', utc=True\n",
    "            )\n",
    "        else:\n",
    "            df['game_dt'] = pd.to_datetime(df['date_utc'], errors='coerce', utc=True)\n",
    "    else:\n",
    "        df['game_dt'] = pd.to_datetime(df.get('date', pd.NaT), errors='coerce')\n",
    "        # if naive, assume UTC\n",
    "        if df['game_dt'].dt.tz is None:\n",
    "            df['game_dt'] = df['game_dt'].dt.tz_localize('UTC')\n",
    "\n",
    "    # Keep a simple sortable date for later (optional)\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    else:\n",
    "        df['date'] = df['game_dt'].dt.tz_convert('UTC').dt.date\n",
    "\n",
    "    # --- 1) Identify base stat names (strip _home/_away) ---\n",
    "    def _base_names(columns):\n",
    "        bases = set()\n",
    "        for c in columns:\n",
    "            if c.endswith('_home'):\n",
    "                bases.add(c[:-5])\n",
    "            elif c.endswith('_away'):\n",
    "                bases.add(c[:-5])\n",
    "        return sorted(bases)\n",
    "\n",
    "    stat_bases = _base_names(df.columns)\n",
    "\n",
    "    # --- 2) Long-format: one row per team per game (home & away views) ---\n",
    "    def _make_team_rows(side):\n",
    "        assert side in ('home','away')\n",
    "        other = 'away' if side == 'home' else 'home'\n",
    "\n",
    "        # map base stat names to (team_col, opp_col) for this perspective\n",
    "        base_map = {}\n",
    "        for b in stat_bases:\n",
    "            team_col = f'{b}_{side}'\n",
    "            opp_col  = f'{b}_{other}'\n",
    "            if team_col in df.columns and opp_col in df.columns:\n",
    "                base_map[b] = (team_col, opp_col)\n",
    "\n",
    "        is_home_val = 1 if side == 'home' else 0\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            'game_id': df['game_id'],\n",
    "            'season' : df['season'],\n",
    "            'date'   : df['date'],\n",
    "            'game_dt': df['game_dt'],\n",
    "            'team'   : df[side],\n",
    "            'opponent': df[other],\n",
    "            'is_home': np.full(len(df), is_home_val, dtype=np.int8),\n",
    "        })\n",
    "\n",
    "        # standardize scores/margins\n",
    "        if f'{side}_score' in df.columns and f'{other}_score' in df.columns:\n",
    "            out['team_score'] = pd.to_numeric(df[f'{side}_score'], errors='coerce')\n",
    "            out['opp_score']  = pd.to_numeric(df[f'{other}_score'], errors='coerce')\n",
    "\n",
    "        if f'{side}_margin' in df.columns and f'{other}_margin' in df.columns:\n",
    "            out['team_margin'] = pd.to_numeric(df[f'{side}_margin'], errors='coerce')\n",
    "            out['opp_margin']  = pd.to_numeric(df[f'{other}_margin'], errors='coerce')\n",
    "\n",
    "        if 'neutral_site' in df.columns:\n",
    "            out['neutral_site'] = pd.Series(df['neutral_site']).fillna(0).astype(int)\n",
    "\n",
    "        # copy per-game stats into standardized columns: <base> and opp_<base>\n",
    "        for b,(tc,oc) in base_map.items():\n",
    "            out[b] = pd.to_numeric(df[tc], errors='coerce')\n",
    "            out[f'opp_{b}'] = pd.to_numeric(df[oc], errors='coerce')\n",
    "\n",
    "        # standardized 1H / 2H points\n",
    "        if f'{side}_1h' in df.columns and f'{other}_1h' in df.columns:\n",
    "            out['points_1h']     = pd.to_numeric(df[f'{side}_1h'], errors='coerce')\n",
    "            out['opp_points_1h'] = pd.to_numeric(df[f'{other}_1h'], errors='coerce')\n",
    "\n",
    "        if f'{side}_2h' in df.columns and f'{other}_2h' in df.columns:\n",
    "            out['points_2h']     = pd.to_numeric(df[f'{side}_2h'], errors='coerce')\n",
    "            out['opp_points_2h'] = pd.to_numeric(df[f'{other}_2h'], errors='coerce')\n",
    "\n",
    "        return out\n",
    "\n",
    "    long_home = _make_team_rows('home')\n",
    "    long_away = _make_team_rows('away')\n",
    "    team_games = pd.concat([long_home, long_away], ignore_index=True)\n",
    "    team_games = team_games.sort_values(['team','season','game_dt','game_id']).reset_index(drop=True)\n",
    "\n",
    "    # --- 3) Rest days ---\n",
    "    # 3a) Historical per-game gaps for rolling features (UNCHANGED)\n",
    "    team_games['prev_game_dt'] = team_games.groupby(['team','season'])['game_dt'].shift(1)\n",
    "    team_games['rest_days_hist'] = (team_games['game_dt'] - team_games['prev_game_dt']).dt.days\n",
    "    team_games['rest_days_hist'] = team_games['rest_days_hist'].fillna(7)\n",
    "\n",
    "    # Rolling averages computed from historical gaps (UNCHANGED)\n",
    "    for w in windows:\n",
    "        team_games[f'ra_rest_days_w{w}'] = (\n",
    "            team_games.groupby(['team','season'])['rest_days_hist']\n",
    "            .transform(lambda s: s.rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "    # 3b) Current rest days for inference (CHANGED):\n",
    "    #     days since the last completed game to \"today_utc\"\n",
    "    last_game_dt = (\n",
    "        team_games.groupby(['team','season'], dropna=False)['game_dt']\n",
    "        .transform('max')\n",
    "    )\n",
    "    # compute per-row current rest (same within a team/season), but we'll only use it on the latest snapshot\n",
    "    team_games['rest_days_current'] = (today_utc - last_game_dt).dt.days.clip(lower=0)\n",
    "\n",
    "    # --- 4) Rolling/EWM features for team & allowed (NO shift for inference) ---\n",
    "    full_bases = [b for b in stat_bases if b in team_games.columns]\n",
    "\n",
    "    def _roll(s, w):  return s.rolling(w, min_periods=1).mean()\n",
    "    def _rstd(s, w):  return s.rolling(w, min_periods=2).std()\n",
    "    def _ewm(s, hl):  return s.ewm(halflife=hl, min_periods=1, adjust=False).mean()\n",
    "\n",
    "    for b in full_bases:\n",
    "        # team rolling\n",
    "        for w in windows:\n",
    "            team_games[f'ra_{b}_w{w}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _roll(s, w))\n",
    "        team_games[f'rstd_{b}_w5'] = team_games.groupby(['team','season'])[b].transform(lambda s: _rstd(s, 5))\n",
    "        team_games[f'ewm_{b}_hl{ewm_halflife}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _ewm(s, ewm_halflife))\n",
    "\n",
    "        # allowed\n",
    "        ob = f'opp_{b}'\n",
    "        if ob in team_games.columns:\n",
    "            for w in windows:\n",
    "                team_games[f'ra_allowed_{b}_w{w}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _roll(s, w))\n",
    "            team_games[f'rstd_allowed_{b}_w5'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _rstd(s, 5))\n",
    "            team_games[f'ewm_allowed_{b}_hl{ewm_halflife}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _ewm(s, ewm_halflife))\n",
    "\n",
    "    # 4b) 1H/2H rolling, allowed\n",
    "    for b in ['points_1h', 'points_2h']:\n",
    "        if b in team_games.columns:\n",
    "            for w in windows:\n",
    "                team_games[f'ra_{b}_w{w}'] = team_games.groupby(['team','season'])[b].transform(lambda s: _roll(s, w))\n",
    "            ob = f'opp_{b}'\n",
    "            if ob in team_games.columns:\n",
    "                for w in windows:\n",
    "                    team_games[f'ra_allowed_{b}_w{w}'] = team_games.groupby(['team','season'])[ob].transform(lambda s: _roll(s, w))\n",
    "\n",
    "    # --- 5) Venue effects (home vs away) ---\n",
    "    if 'team_margin' in team_games.columns:\n",
    "        for w in windows:\n",
    "            team_games[f'ra_margin_homeonly_w{w}'] = (\n",
    "                team_games.groupby(['team','season','is_home'])['team_margin'].transform(lambda s: _roll(s, w))\n",
    "            )\n",
    "        for w in windows:\n",
    "            team_games[f'ra_margin_w{w}'] = team_games.groupby(['team','season'])['team_margin'].transform(lambda s: _roll(s, w))\n",
    "\n",
    "    # --- 6) Recent scoring form ---\n",
    "    if 'team_score' in team_games.columns and 'opp_score' in team_games.columns:\n",
    "        for w in windows:\n",
    "            pf = team_games.groupby(['team','season'])['team_score'].transform(lambda s: _roll(s, w))\n",
    "            pa = team_games.groupby(['team','season'])['opp_score' ].transform(lambda s: _roll(s, w))\n",
    "            team_games[f'ra_points_for_w{w}']     = pf\n",
    "            team_games[f'ra_points_against_w{w}'] = pa\n",
    "            team_games[f'ra_point_diff_w{w}']     = pf - pa\n",
    "\n",
    "    # --- 7) Build the \"pregame\" (inference) feature table ---\n",
    "    # We exclude raw current-game single-game columns that could leak (the current box score isn’t known)\n",
    "    leak_cols = ['points_1h','opp_points_1h','points_2h','opp_points_2h',\n",
    "                 'team_score','opp_score','team_margin','opp_margin','prev_game_dt']\n",
    "    raw_stat_cols = full_bases + [f'opp_{b}' for b in full_bases] + leak_cols\n",
    "    raw_stat_cols = [c for c in raw_stat_cols if c in team_games.columns]\n",
    "\n",
    "    feature_cols = [c for c in team_games.columns if c not in (raw_stat_cols + ['opponent'])]\n",
    "    pregame_team_features = team_games[feature_cols + ['opponent']].copy()\n",
    "\n",
    "    # --- 8) Latest snapshot per team-season (no leak; includes most recent game) ---\n",
    "    latest_snapshot = (\n",
    "        pregame_team_features\n",
    "        .sort_values(['team','season','game_dt','game_id'])\n",
    "        .groupby(['team','season'], as_index=False, sort=False)\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Overwrite 'rest_days' in the latest snapshot with the \"today-based\" value\n",
    "    # (Keep rolling features ra_rest_days_w* as-is from historical gaps.)\n",
    "    if 'rest_days_current' in latest_snapshot.columns:\n",
    "        latest_snapshot['rest_days'] = latest_snapshot['rest_days_current']\n",
    "        latest_snapshot = latest_snapshot.drop(columns=['rest_days_current'])\n",
    "\n",
    "    # --- 9) Match your requested output column list (keep those that exist) ---\n",
    "    wanted = ['game_id', 'team', 'rest_days',\n",
    "              'ra_rest_days_w1','ra_rest_days_w3','ra_rest_days_w5','ra_rest_days_w10',\n",
    "              'ra_assists_w1','ra_allowed_assists_w1','ra_assists_w3','ra_allowed_assists_w3',\n",
    "              'ra_assists_w5','ra_allowed_assists_w5','ra_assists_w10','ra_allowed_assists_w10',\n",
    "              'rstd_assists_w5','ewm_assists_hl5','rstd_allowed_assists_w5','ewm_allowed_assists_hl5',\n",
    "              'ra_blocks_w1','ra_allowed_blocks_w1','ra_blocks_w3','ra_allowed_blocks_w3',\n",
    "              'ra_blocks_w5','ra_allowed_blocks_w5','ra_blocks_w10','ra_allowed_blocks_w10',\n",
    "              'rstd_blocks_w5','ewm_blocks_hl5','rstd_allowed_blocks_w5','ewm_allowed_blocks_hl5',\n",
    "              'ra_defensiveRebounds_w1','ra_allowed_defensiveRebounds_w1','ra_defensiveRebounds_w3',\n",
    "              'ra_allowed_defensiveRebounds_w3','ra_defensiveRebounds_w5','ra_allowed_defensiveRebounds_w5',\n",
    "              'ra_defensiveRebounds_w10','ra_allowed_defensiveRebounds_w10',\n",
    "              'rstd_defensiveRebounds_w5','ewm_defensiveRebounds_hl5',\n",
    "              'rstd_allowed_defensiveRebounds_w5','ewm_allowed_defensiveRebounds_hl5',\n",
    "              'ra_fastBreakPoints_w1','ra_allowed_fastBreakPoints_w1','ra_fastBreakPoints_w3',\n",
    "              'ra_allowed_fastBreakPoints_w3','ra_fastBreakPoints_w5','ra_allowed_fastBreakPoints_w5',\n",
    "              'ra_fastBreakPoints_w10','ra_allowed_fastBreakPoints_w10',\n",
    "              'rstd_fastBreakPoints_w5','ewm_fastBreakPoints_hl5',\n",
    "              'rstd_allowed_fastBreakPoints_w5','ewm_allowed_fastBreakPoints_hl5',\n",
    "              'ra_flagrantFouls_w1','ra_allowed_flagrantFouls_w1','ra_flagrantFouls_w3',\n",
    "              'ra_allowed_flagrantFouls_w3','ra_flagrantFouls_w5','ra_allowed_flagrantFouls_w5',\n",
    "              'ra_flagrantFouls_w10','ra_allowed_flagrantFouls_w10',\n",
    "              'rstd_flagrantFouls_w5','ewm_flagrantFouls_hl5',\n",
    "              'rstd_allowed_flagrantFouls_w5','ewm_allowed_flagrantFouls_hl5',\n",
    "              'ra_fouls_w1','ra_allowed_fouls_w1','ra_fouls_w3','ra_allowed_fouls_w3',\n",
    "              'ra_fouls_w5','ra_allowed_fouls_w5','ra_fouls_w10','ra_allowed_fouls_w10',\n",
    "              'rstd_fouls_w5','ewm_fouls_hl5','rstd_allowed_fouls_w5','ewm_allowed_fouls_hl5',\n",
    "              'ra_offensiveRebounds_w1','ra_allowed_offensiveRebounds_w1','ra_offensiveRebounds_w3',\n",
    "              'ra_allowed_offensiveRebounds_w3','ra_offensiveRebounds_w5','ra_allowed_offensiveRebounds_w5',\n",
    "              'ra_offensiveRebounds_w10','ra_allowed_offensiveRebounds_w10',\n",
    "              'rstd_offensiveRebounds_w5','ewm_offensiveRebounds_hl5',\n",
    "              'rstd_allowed_offensiveRebounds_w5','ewm_allowed_offensiveRebounds_hl5',\n",
    "              'ra_pointsInPaint_w1','ra_allowed_pointsInPaint_w1','ra_pointsInPaint_w3',\n",
    "              'ra_allowed_pointsInPaint_w3','ra_pointsInPaint_w5','ra_allowed_pointsInPaint_w5',\n",
    "              'ra_pointsInPaint_w10','ra_allowed_pointsInPaint_w10',\n",
    "              'rstd_pointsInPaint_w5','ewm_pointsInPaint_hl5',\n",
    "              'rstd_allowed_pointsInPaint_w5','ewm_allowed_pointsInPaint_hl5',\n",
    "              'ra_steals_w1','ra_allowed_steals_w1','ra_steals_w3','ra_allowed_steals_w3',\n",
    "              'ra_steals_w5','ra_allowed_steals_w5','ra_steals_w10','ra_allowed_steals_w10',\n",
    "              'rstd_steals_w5','ewm_steals_hl5','rstd_allowed_steals_w5','ewm_allowed_steals_hl5',\n",
    "              'ra_technicalFouls_w1','ra_allowed_technicalFouls_w1','ra_technicalFouls_w3',\n",
    "              'ra_allowed_technicalFouls_w3','ra_technicalFouls_w5','ra_allowed_technicalFouls_w5',\n",
    "              'ra_technicalFouls_w10','ra_allowed_technicalFouls_w10',\n",
    "              'rstd_technicalFouls_w5','ewm_technicalFouls_hl5',\n",
    "              'rstd_allowed_technicalFouls_w5','ewm_allowed_technicalFouls_hl5',\n",
    "              'ra_totalRebounds_w1','ra_allowed_totalRebounds_w1','ra_totalRebounds_w3',\n",
    "              'ra_allowed_totalRebounds_w3','ra_totalRebounds_w5','ra_allowed_totalRebounds_w5',\n",
    "              'ra_totalRebounds_w10','ra_allowed_totalRebounds_w10',\n",
    "              'rstd_totalRebounds_w5','ewm_totalRebounds_hl5',\n",
    "              'rstd_allowed_totalRebounds_w5','ewm_allowed_totalRebounds_hl5',\n",
    "              'ra_turnoverPoints_w1','ra_allowed_turnoverPoints_w1','ra_turnoverPoints_w3',\n",
    "              'ra_allowed_turnoverPoints_w3','ra_turnoverPoints_w5','ra_allowed_turnoverPoints_w5',\n",
    "              'ra_turnoverPoints_w10','ra_allowed_turnoverPoints_w10',\n",
    "              'rstd_turnoverPoints_w5','ewm_turnoverPoints_hl5',\n",
    "              'rstd_allowed_turnoverPoints_w5','ewm_allowed_turnoverPoints_hl5',\n",
    "              'ra_turnovers_w1','ra_allowed_turnovers_w1','ra_turnovers_w3','ra_allowed_turnovers_w3',\n",
    "              'ra_turnovers_w5','ra_allowed_turnovers_w5','ra_turnovers_w10','ra_allowed_turnovers_w10',\n",
    "              'rstd_turnovers_w5','ewm_turnovers_hl5','rstd_allowed_turnovers_w5','ewm_allowed_turnovers_hl5',\n",
    "              'ra_points_1h_w1','ra_points_1h_w3','ra_points_1h_w5','ra_points_1h_w10',\n",
    "              'ra_allowed_points_1h_w1','ra_allowed_points_1h_w3','ra_allowed_points_1h_w5','ra_allowed_points_1h_w10',\n",
    "              'ra_points_2h_w1','ra_points_2h_w3','ra_points_2h_w5','ra_points_2h_w10',\n",
    "              'ra_allowed_points_2h_w1','ra_allowed_points_2h_w3','ra_allowed_points_2h_w5','ra_allowed_points_2h_w10',\n",
    "              'ra_margin_homeonly_w1','ra_margin_homeonly_w3','ra_margin_homeonly_w5','ra_margin_homeonly_w10',\n",
    "              'ra_points_for_w1','ra_points_against_w1','ra_point_diff_w1',\n",
    "              'ra_points_for_w3','ra_points_against_w3','ra_point_diff_w3',\n",
    "              'ra_points_for_w5','ra_points_against_w5','ra_point_diff_w5',\n",
    "              'ra_points_for_w10','ra_points_against_w10','ra_point_diff_w10',\n",
    "              'ra_margin_w1','ra_margin_w3','ra_margin_w5','ra_margin_w10'\n",
    "             ]\n",
    "\n",
    "    keep = [c for c in wanted if c in latest_snapshot.columns]\n",
    "    features_3 = latest_snapshot[['team'] + keep] if 'team' not in keep else latest_snapshot[keep]\n",
    "\n",
    "    return features_3\n",
    "\n",
    "# -----------------------\n",
    "# USAGE\n",
    "# -----------------------\n",
    "features_3 = build_cbb_features_inference(\n",
    "    merged_df[['game_id','season','date','date_utc','time_utc','neutral_site','home','away',\n",
    "               'home_1h','away_1h','home_2h','away_2h','home_score','away_score',\n",
    "               'home_margin','away_margin',\n",
    "               'assists_home','fouls_home','technicalFouls_home','flagrantFouls_home',\n",
    "               'totalRebounds_home','offensiveRebounds_home','defensiveRebounds_home',\n",
    "               'pointsInPaint_home','turnovers_home','turnoverPoints_home','steals_home',\n",
    "               'blocks_home','fastBreakPoints_home',\n",
    "               'assists_away','fouls_away','technicalFouls_away','flagrantFouls_away',\n",
    "               'totalRebounds_away','offensiveRebounds_away','defensiveRebounds_away',\n",
    "               'pointsInPaint_away','turnovers_away','turnoverPoints_away','steals_away',\n",
    "               'blocks_away','fastBreakPoints_away']]\n",
    ")\n",
    "\n",
    "# features_3: one row per team-season, with the rolling/EWM features\n",
    "assert len(set(list(features_3.columns)) - set(['game_id', 'team', 'rest_days', 'ra_rest_days_w1', 'ra_rest_days_w3', 'ra_rest_days_w5', 'ra_rest_days_w10', 'ra_assists_w1', 'ra_allowed_assists_w1', 'ra_assists_w3', 'ra_allowed_assists_w3', 'ra_assists_w5', 'ra_allowed_assists_w5', 'ra_assists_w10', 'ra_allowed_assists_w10', 'rstd_assists_w5', 'ewm_assists_hl5', 'rstd_allowed_assists_w5', 'ewm_allowed_assists_hl5', 'ra_blocks_w1', 'ra_allowed_blocks_w1', 'ra_blocks_w3', 'ra_allowed_blocks_w3', 'ra_blocks_w5', 'ra_allowed_blocks_w5', 'ra_blocks_w10', 'ra_allowed_blocks_w10', 'rstd_blocks_w5', 'ewm_blocks_hl5', 'rstd_allowed_blocks_w5', 'ewm_allowed_blocks_hl5', 'ra_defensiveRebounds_w1', 'ra_allowed_defensiveRebounds_w1', 'ra_defensiveRebounds_w3', 'ra_allowed_defensiveRebounds_w3', 'ra_defensiveRebounds_w5', 'ra_allowed_defensiveRebounds_w5', 'ra_defensiveRebounds_w10', 'ra_allowed_defensiveRebounds_w10', 'rstd_defensiveRebounds_w5', 'ewm_defensiveRebounds_hl5', 'rstd_allowed_defensiveRebounds_w5', 'ewm_allowed_defensiveRebounds_hl5', 'ra_fastBreakPoints_w1', 'ra_allowed_fastBreakPoints_w1', 'ra_fastBreakPoints_w3', 'ra_allowed_fastBreakPoints_w3', 'ra_fastBreakPoints_w5', 'ra_allowed_fastBreakPoints_w5', 'ra_fastBreakPoints_w10', 'ra_allowed_fastBreakPoints_w10', 'rstd_fastBreakPoints_w5', 'ewm_fastBreakPoints_hl5', 'rstd_allowed_fastBreakPoints_w5', 'ewm_allowed_fastBreakPoints_hl5', 'ra_flagrantFouls_w1', 'ra_allowed_flagrantFouls_w1', 'ra_flagrantFouls_w3', 'ra_allowed_flagrantFouls_w3', 'ra_flagrantFouls_w5', 'ra_allowed_flagrantFouls_w5', 'ra_flagrantFouls_w10', 'ra_allowed_flagrantFouls_w10', 'rstd_flagrantFouls_w5', 'ewm_flagrantFouls_hl5', 'rstd_allowed_flagrantFouls_w5', 'ewm_allowed_flagrantFouls_hl5', 'ra_fouls_w1', 'ra_allowed_fouls_w1', 'ra_fouls_w3', 'ra_allowed_fouls_w3', 'ra_fouls_w5', 'ra_allowed_fouls_w5', 'ra_fouls_w10', 'ra_allowed_fouls_w10', 'rstd_fouls_w5', 'ewm_fouls_hl5', 'rstd_allowed_fouls_w5', 'ewm_allowed_fouls_hl5', 'ra_offensiveRebounds_w1', 'ra_allowed_offensiveRebounds_w1', 'ra_offensiveRebounds_w3', 'ra_allowed_offensiveRebounds_w3', 'ra_offensiveRebounds_w5', 'ra_allowed_offensiveRebounds_w5', 'ra_offensiveRebounds_w10', 'ra_allowed_offensiveRebounds_w10', 'rstd_offensiveRebounds_w5', 'ewm_offensiveRebounds_hl5', 'rstd_allowed_offensiveRebounds_w5', 'ewm_allowed_offensiveRebounds_hl5', 'ra_pointsInPaint_w1', 'ra_allowed_pointsInPaint_w1', 'ra_pointsInPaint_w3', 'ra_allowed_pointsInPaint_w3', 'ra_pointsInPaint_w5', 'ra_allowed_pointsInPaint_w5', 'ra_pointsInPaint_w10', 'ra_allowed_pointsInPaint_w10', 'rstd_pointsInPaint_w5', 'ewm_pointsInPaint_hl5', 'rstd_allowed_pointsInPaint_w5', 'ewm_allowed_pointsInPaint_hl5', 'ra_steals_w1', 'ra_allowed_steals_w1', 'ra_steals_w3', 'ra_allowed_steals_w3', 'ra_steals_w5', 'ra_allowed_steals_w5', 'ra_steals_w10', 'ra_allowed_steals_w10', 'rstd_steals_w5', 'ewm_steals_hl5', 'rstd_allowed_steals_w5', 'ewm_allowed_steals_hl5', 'ra_technicalFouls_w1', 'ra_allowed_technicalFouls_w1', 'ra_technicalFouls_w3', 'ra_allowed_technicalFouls_w3', 'ra_technicalFouls_w5', 'ra_allowed_technicalFouls_w5', 'ra_technicalFouls_w10', 'ra_allowed_technicalFouls_w10', 'rstd_technicalFouls_w5', 'ewm_technicalFouls_hl5', 'rstd_allowed_technicalFouls_w5', 'ewm_allowed_technicalFouls_hl5', 'ra_totalRebounds_w1', 'ra_allowed_totalRebounds_w1', 'ra_totalRebounds_w3', 'ra_allowed_totalRebounds_w3', 'ra_totalRebounds_w5', 'ra_allowed_totalRebounds_w5', 'ra_totalRebounds_w10', 'ra_allowed_totalRebounds_w10', 'rstd_totalRebounds_w5', 'ewm_totalRebounds_hl5', 'rstd_allowed_totalRebounds_w5', 'ewm_allowed_totalRebounds_hl5', 'ra_turnoverPoints_w1', 'ra_allowed_turnoverPoints_w1', 'ra_turnoverPoints_w3', 'ra_allowed_turnoverPoints_w3', 'ra_turnoverPoints_w5', 'ra_allowed_turnoverPoints_w5', 'ra_turnoverPoints_w10', 'ra_allowed_turnoverPoints_w10', 'rstd_turnoverPoints_w5', 'ewm_turnoverPoints_hl5', 'rstd_allowed_turnoverPoints_w5', 'ewm_allowed_turnoverPoints_hl5', 'ra_turnovers_w1', 'ra_allowed_turnovers_w1', 'ra_turnovers_w3', 'ra_allowed_turnovers_w3', 'ra_turnovers_w5', 'ra_allowed_turnovers_w5', 'ra_turnovers_w10', 'ra_allowed_turnovers_w10', 'rstd_turnovers_w5', 'ewm_turnovers_hl5', 'rstd_allowed_turnovers_w5', 'ewm_allowed_turnovers_hl5', 'ra_points_1h_w1', 'ra_points_1h_w3', 'ra_points_1h_w5', 'ra_points_1h_w10', 'ra_allowed_points_1h_w1', 'ra_allowed_points_1h_w3', 'ra_allowed_points_1h_w5', 'ra_allowed_points_1h_w10', 'ra_points_2h_w1', 'ra_points_2h_w3', 'ra_points_2h_w5', 'ra_points_2h_w10', 'ra_allowed_points_2h_w1', 'ra_allowed_points_2h_w3', 'ra_allowed_points_2h_w5', 'ra_allowed_points_2h_w10', 'ra_margin_homeonly_w1', 'ra_margin_homeonly_w3', 'ra_margin_homeonly_w5', 'ra_margin_homeonly_w10', 'ra_points_for_w1', 'ra_points_against_w1', 'ra_point_diff_w1', 'ra_points_for_w3', 'ra_points_against_w3', 'ra_point_diff_w3', 'ra_points_for_w5', 'ra_points_against_w5', 'ra_point_diff_w5', 'ra_points_for_w10', 'ra_points_against_w10', 'ra_point_diff_w10', 'ra_margin_w1', 'ra_margin_w3', 'ra_margin_w5', 'ra_margin_w10'])) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "game_info = pd.read_csv(\"daily-games/daily.csv\", index_col=0)\n",
    "game_info['game_id']  = game_info['game_id'].astype(str)\n",
    "features_1['game_id'] = features_1['game_id'].astype(str)\n",
    "features_2['game_id'] = features_2['game_id'].astype(str)\n",
    "features_3['game_id'] = features_3['game_id'].astype(str)\n",
    "game_info = game_info.merge(features_1, on=\"game_id\", how=\"left\")\n",
    "\n",
    "home_merge = features_2.copy()\n",
    "home_merge = home_merge.rename(columns=lambda c: f\"{c}_home\" if c not in [\"game_id\", \"team\", \"opponent\"] else c)\n",
    "merged_home = game_info.merge(\n",
    "    home_merge,\n",
    "    left_on=\"home\",\n",
    "    right_on=\"team\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"team\", \"opponent\"])\n",
    "\n",
    "# --- AWAY TEAM MERGE ---\n",
    "away_merge = features_2.copy()\n",
    "away_merge = away_merge.rename(columns=lambda c: f\"{c}_away\" if c not in [\"game_id\", \"team\", \"opponent\"] else c)\n",
    "game_info = merged_home.merge(\n",
    "    away_merge,\n",
    "    left_on=\"away\",\n",
    "    right_on=\"team\",\n",
    "    how=\"left\",\n",
    ").drop(columns=[\"team\", \"opponent\"])\n",
    "\n",
    "key_cols = ['game_id', 'team']\n",
    "\n",
    "# --- HOME merge ---\n",
    "home_feats = features_3.copy()\n",
    "home_feats = home_feats.rename(columns=lambda c: f\"{c}_home\" if c not in key_cols else c)\n",
    "\n",
    "out = game_info.merge(\n",
    "    home_feats,\n",
    "    left_on='home',\n",
    "    right_on='team',\n",
    "    how='left',\n",
    ").drop(columns=['team'])\n",
    "\n",
    "# --- AWAY merge ---\n",
    "away_feats = features_3.copy()\n",
    "away_feats = away_feats.rename(columns=lambda c: f\"{c}_away\" if c not in key_cols else c)\n",
    "\n",
    "game_info = out.merge(\n",
    "    away_feats,\n",
    "    left_on='away',\n",
    "    right_on='team',\n",
    "    how='left',\n",
    ").drop(columns=['team'])\n",
    "\n",
    "game_info = game_info.dropna(subset=[\"home\", \"away\"])\n",
    "os.makedirs(f\"data/inference/{DATE}/\", exist_ok=True)\n",
    "game_info[~((game_info['ra_allowed_defensiveRebounds_w1_home'].isna()) & (game_info['ra_allowed_defensiveRebounds_w1_home'].isna()))].to_csv(f\"data/inference/{DATE}/inference_data.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id_x</th>\n",
       "      <th>date</th>\n",
       "      <th>date_key</th>\n",
       "      <th>date_utc</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>neutral_site</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>conf_home</th>\n",
       "      <th>conf_away</th>\n",
       "      <th>...</th>\n",
       "      <th>ra_points_for_w5_away</th>\n",
       "      <th>ra_points_against_w5_away</th>\n",
       "      <th>ra_point_diff_w5_away</th>\n",
       "      <th>ra_points_for_w10_away</th>\n",
       "      <th>ra_points_against_w10_away</th>\n",
       "      <th>ra_point_diff_w10_away</th>\n",
       "      <th>ra_margin_w1_away</th>\n",
       "      <th>ra_margin_w3_away</th>\n",
       "      <th>ra_margin_w5_away</th>\n",
       "      <th>ra_margin_w10_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>401823036</td>\n",
       "      <td>20251106</td>\n",
       "      <td>20251106</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>00:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Maryland Eastern Shore</td>\n",
       "      <td>SEC</td>\n",
       "      <td>MEAC</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>401823021</td>\n",
       "      <td>20251106</td>\n",
       "      <td>20251106</td>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>01:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Southern</td>\n",
       "      <td>BE</td>\n",
       "      <td>SWAC</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_id_x      date  date_key    date_utc time_utc  neutral_site  \\\n",
       "20  401823036  20251106  20251106  2025-11-06   00:00Z             0   \n",
       "21  401823021  20251106  20251106  2025-11-06   01:00Z             0   \n",
       "\n",
       "         home                    away conf_home conf_away  ...  \\\n",
       "20    Georgia  Maryland Eastern Shore       SEC      MEAC  ...   \n",
       "21  Marquette                Southern        BE      SWAC  ...   \n",
       "\n",
       "    ra_points_for_w5_away  ra_points_against_w5_away  ra_point_diff_w5_away  \\\n",
       "20                   52.0                       56.0                   -4.0   \n",
       "21                   77.0                      109.0                  -32.0   \n",
       "\n",
       "    ra_points_for_w10_away  ra_points_against_w10_away  \\\n",
       "20                    52.0                        56.0   \n",
       "21                    77.0                       109.0   \n",
       "\n",
       "    ra_point_diff_w10_away  ra_margin_w1_away  ra_margin_w3_away  \\\n",
       "20                    -4.0               -4.0               -4.0   \n",
       "21                   -32.0              -32.0              -32.0   \n",
       "\n",
       "    ra_margin_w5_away  ra_margin_w10_away  \n",
       "20               -4.0                -4.0  \n",
       "21              -32.0               -32.0  \n",
       "\n",
       "[2 rows x 516 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_info[~((game_info['ra_allowed_defensiveRebounds_w1_home'].isna()) & (game_info['ra_allowed_defensiveRebounds_w1_home'].isna()))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03eca27aa3e5b0c2bf98348f6751bc7dc08663828d24c367008019d5f5934307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
