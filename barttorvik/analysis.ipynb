{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATE = \"2025-11-06\"\n",
    "CLEAN_DATE = DATE.replace(\"-\",\"\")\n",
    "daily_preds = pd.read_csv(f\"data/predictions/{CLEAN_DATE}/preds.csv\")\n",
    "\n",
    "spreads_df = pd.read_csv(f\"data/odds/{DATE}/spreads_final.csv\")\n",
    "totals_df = pd.read_csv(f\"data/odds/{DATE}/totals_final.csv\")\n",
    "\n",
    "map = pd.read_csv(\"data/teams/odds_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_ratio(num, den):\n",
    "    den = np.where(np.abs(den) < 1e-8, np.nan, den)\n",
    "    return np.where(np.isnan(num) | np.isnan(den), np.nan, num / den)\n",
    "\n",
    "def reconcile_game(row, \n",
    "                   w_score=1.0, \n",
    "                   w_sumhalves=1.0, \n",
    "                   w_margin=1.0,\n",
    "                   use_both_margins=False):\n",
    "    \"\"\"\n",
    "    Reconcile one game's predictions via weighted least squares.\n",
    "    \n",
    "    Unknowns: x = [S_h, S_a]^T (reconciled home & away totals)\n",
    "    Observations (linear):\n",
    "      - pred_home_score          ≈ [1, 0] @ x\n",
    "      - pred_away_score          ≈ [0, 1] @ x\n",
    "      - (pred_home_1h+2h)        ≈ [1, 0] @ x\n",
    "      - (pred_away_1h+2h)        ≈ [0, 1] @ x\n",
    "      - margin (home - away)     ≈ [1, -1] @ x\n",
    "\n",
    "    Weights (inverse-variance proxies): w_score, w_sumhalves, w_margin.\n",
    "    If use_both_margins is True, both home and away margins are used\n",
    "    (the away margin is negated to be home - away); otherwise we use the\n",
    "    home margin if present, else the negated away margin if present.\n",
    "    \"\"\"\n",
    "\n",
    "    A_rows, y_vals, w_vals = [], [], []\n",
    "\n",
    "    # Pull columns, allowing for missing values (NaNs)\n",
    "    ph1, ph2 = row.get('pred_home_1h'), row.get('pred_home_2h')\n",
    "    pa1, pa2 = row.get('pred_away_1h'), row.get('pred_away_2h')\n",
    "    Sh, Sa = row.get('pred_home_score'), row.get('pred_away_score')\n",
    "    Mh, Ma = row.get('pred_home_margin'), row.get('pred_away_margin')\n",
    "\n",
    "    # Full score observations\n",
    "    if pd.notna(Sh):\n",
    "        A_rows.append([1.0, 0.0]); y_vals.append(Sh); w_vals.append(w_score)\n",
    "    if pd.notna(Sa):\n",
    "        A_rows.append([0.0, 1.0]); y_vals.append(Sa); w_vals.append(w_score)\n",
    "\n",
    "    # Sum-of-halves observations\n",
    "    if pd.notna(ph1) and pd.notna(ph2):\n",
    "        A_rows.append([1.0, 0.0]); y_vals.append(ph1 + ph2); w_vals.append(w_sumhalves)\n",
    "    if pd.notna(pa1) and pd.notna(pa2):\n",
    "        A_rows.append([0.0, 1.0]); y_vals.append(pa1 + pa2); w_vals.append(w_sumhalves)\n",
    "\n",
    "    # Margin observations (home - away)\n",
    "    if use_both_margins:\n",
    "        # Use both, each with half-weight to avoid double-counting\n",
    "        used_any = False\n",
    "        if pd.notna(Mh):\n",
    "            A_rows.append([1.0, -1.0]); y_vals.append(Mh); w_vals.append(w_margin * 0.5)\n",
    "            used_any = True\n",
    "        if pd.notna(Ma):\n",
    "            A_rows.append([1.0, -1.0]); y_vals.append(-Ma); w_vals.append(w_margin * 0.5)\n",
    "            used_any = True\n",
    "        # If neither present, nothing is added.\n",
    "    else:\n",
    "        if pd.notna(Mh):\n",
    "            A_rows.append([1.0, -1.0]); y_vals.append(Mh); w_vals.append(w_margin)\n",
    "        elif pd.notna(Ma):\n",
    "            A_rows.append([1.0, -1.0]); y_vals.append(-Ma); w_vals.append(w_margin)\n",
    "\n",
    "    # If we have no observations, return NaNs\n",
    "    if len(A_rows) == 0:\n",
    "        return pd.Series({\n",
    "            'cons_home_score': np.nan,\n",
    "            'cons_away_score': np.nan,\n",
    "            'cons_margin':     np.nan,\n",
    "            'cons_home_1h':    np.nan,\n",
    "            'cons_home_2h':    np.nan,\n",
    "            'cons_away_1h':    np.nan,\n",
    "            'cons_away_2h':    np.nan\n",
    "        })\n",
    "\n",
    "    A = np.asarray(A_rows, dtype=float)        # shape (m, 2)\n",
    "    y = np.asarray(y_vals, dtype=float)        # shape (m,)\n",
    "    w = np.asarray(w_vals, dtype=float)        # shape (m,)\n",
    "\n",
    "    # Weighted least squares: solve argmin || W^{1/2}(Ax - y) ||^2\n",
    "    Wsqrt = np.sqrt(w)[:, None]                # shape (m,1)\n",
    "    Aw = A * Wsqrt                             # (m,2)\n",
    "    yw = y * Wsqrt.ravel()                     # (m,)\n",
    "\n",
    "    # Solve via QR/lstsq for numerical stability\n",
    "    x_hat, *_ = np.linalg.lstsq(Aw, yw, rcond=None)\n",
    "    S_h, S_a = x_hat[0], x_hat[1]\n",
    "    M = S_h - S_a\n",
    "\n",
    "    # Allocate halves using observed split ratios (if available)\n",
    "    # If no halves exist, we leave halves as NaN but totals/margin stand.\n",
    "    home_sum_halves = (ph1 + ph2) if (pd.notna(ph1) and pd.notna(ph2)) else np.nan\n",
    "    away_sum_halves = (pa1 + pa2) if (pd.notna(pa1) and pd.notna(pa2)) else np.nan\n",
    "\n",
    "    # Ratios of 1H within sum-of-halves (shrinkage could be added if needed)\n",
    "    rh = _safe_ratio(ph1, home_sum_halves) if pd.notna(home_sum_halves) else np.nan\n",
    "    ra = _safe_ratio(pa1, away_sum_halves) if pd.notna(away_sum_halves) else np.nan\n",
    "\n",
    "    cons_home_1h = rh * S_h if pd.notna(rh) else np.nan\n",
    "    cons_home_2h = (1 - rh) * S_h if pd.notna(rh) else np.nan\n",
    "    cons_away_1h = ra * S_a if pd.notna(ra) else np.nan\n",
    "    cons_away_2h = (1 - ra) * S_a if pd.notna(ra) else np.nan\n",
    "\n",
    "    return pd.Series({\n",
    "        'cons_home_score': S_h,\n",
    "        'cons_away_score': S_a,\n",
    "        'cons_margin':     M,\n",
    "        'cons_home_1h':    cons_home_1h,\n",
    "        'cons_home_2h':    cons_home_2h,\n",
    "        'cons_away_1h':    cons_away_1h,\n",
    "        'cons_away_2h':    cons_away_2h\n",
    "    })\n",
    "\n",
    "def reconcile_dataframe(df,\n",
    "                        w_score=1.0,\n",
    "                        w_sumhalves=1.0,\n",
    "                        w_margin=1.0,\n",
    "                        use_both_margins=False):\n",
    "    \"\"\"\n",
    "    Apply reconciliation to all rows in a dataframe that contains columns:\n",
    "      pred_home_1h, pred_home_2h, pred_home_score, pred_home_margin\n",
    "      pred_away_1h, pred_away_2h, pred_away_score, pred_away_margin\n",
    "\n",
    "    Returns a copy with appended consensus columns.\n",
    "    \"\"\"\n",
    "    required_any = [\n",
    "        # at least some of these should exist; we check per-row\n",
    "        'pred_home_1h','pred_home_2h','pred_home_score','pred_home_margin',\n",
    "        'pred_away_1h','pred_away_2h','pred_away_score','pred_away_margin'\n",
    "    ]\n",
    "    for c in required_any:\n",
    "        if c not in df.columns:\n",
    "            # Create if missing so per-row logic can gracefully handle NaNs\n",
    "            df[c] = np.nan\n",
    "\n",
    "    out = df.apply(\n",
    "        lambda r: reconcile_game(\n",
    "            r,\n",
    "            w_score=w_score,\n",
    "            w_sumhalves=w_sumhalves,\n",
    "            w_margin=w_margin,\n",
    "            use_both_margins=use_both_margins\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    return pd.concat([df.reset_index(drop=True), out], axis=1)\n",
    "\n",
    "# ---- Example usage ----\n",
    "if __name__ == \"__main__\":\n",
    "    # Example schema; plug in your dataframe 'df' with matching columns.\n",
    "    # df = pd.read_csv(\"your_predictions.csv\")\n",
    "    result = reconcile_dataframe(daily_preds, w_score=1.0, w_sumhalves=1.0, w_margin=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['cons_1h_total'] = result['cons_away_1h'] + result['cons_home_1h']\n",
    "result['cons_total'] = result['cons_home_score'] + result['cons_away_score']\n",
    "result['cons_2h_total'] = result['cons_away_2h'] + result['cons_home_2h']\n",
    "result = result[[\"date\", \"home\", \"away\", \"cons_home_score\", \"cons_away_score\", \"cons_margin\", \"cons_total\", \"cons_home_1h\", \"cons_home_2h\", \"cons_away_1h\", \"cons_away_2h\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = [\"date\", \"home\", \"away\", \"home_score\", \"away_score\", \"margin\", \"total\", \"home_1h\", \"home_2h\", \"away_1h\", \"away_2h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_df = totals_df.merge(map, left_on=\"home\", right_on=\"odds\")[[\"espn\", \"open\", \"current\", \"movement\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.merge(totals_df, left_on='home', right_on='espn')[[\"date\", \"home\", \"away\", \"home_score\", \"away_score\", \"margin\", \"total\", \"home_1h\", \"home_2h\", \"away_1h\", \"away_2h\", \"open\", \"current\", \"movement\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = ['date', 'home', 'away', 'home_score', 'away_score', 'margin', 'total',\n",
    "       'home_1h', 'home_2h', 'away_1h', 'away_2h', 'total_open', 'total_current',\n",
    "       'total_movement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreads_df = spreads_df.merge(map, left_on=\"home\", right_on=\"odds\")[[\"espn\", \"open\", \"current\", \"movement\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.merge(spreads_df, left_on='home', right_on='espn')[[\"date\", \"home\", \"away\", \"home_score\", \"away_score\", \"margin\", \"total\", \"home_1h\", \"home_2h\", \"away_1h\", \"away_2h\", 'total_open', 'total_current', 'total_movement', \"open\", \"current\", \"movement\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = ['date', 'home', 'away', 'home_score', 'away_score', 'margin', 'total',\n",
    "       'home_1h', 'home_2h', 'away_1h', 'away_2h', 'total_open',\n",
    "       'total_current', 'total_movement', 'spread_open', 'spread_current', 'spread_movement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['total_diff'] = abs(result['total'] - result['total_current'])\n",
    "result['margin_diff'] = abs(result['margin'] - result['spread_current'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"/Users/nickdimmitt/Desktop/daily_preds.csv\")\n",
    "result.to_csv(f\"data/predictions/{CLEAN_DATE}/daily_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03eca27aa3e5b0c2bf98348f6751bc7dc08663828d24c367008019d5f5934307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
